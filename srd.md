Ghostagotchi â€“ Software Requirements Specification
1. Overview and Objectives
Project Overview: Ghostagotchi is a cross-platform AI-powered virtual ghost pet application. It combines mobile augmented reality, web interactivity, and AI-driven chat into one cohesive experience â€“ aptly fitting the Frankenstein category of the Kiroween hackathon (stitching together disparate technologies into one app[1]). In Ghostagotchi, each user adopts a friendly ghost as a pet, cares for it Tamagotchi-style, and interacts via natural language conversations. The project is built using modern tools â€“ an iOS app (SwiftUI, UIKit, ARKit) for an immersive AR ghost experience, and a Next.js web dashboard for broad accessibility â€“ all backed by a unified cloud backend.
Objectives: The primary goals of Ghostagotchi are:
â€¢	Engaging Pet Experience: Create a fun and spooky-yet-cute ghost pet that users can care for, play with, and chat with. Using Appleâ€™s ARKit, the ghost comes to life in the userâ€™s real environment through augmented reality on iOS. The ghost has basic â€œneedsâ€ (like hunger or mood) that the user must manage, similar to a digital pet, fostering ongoing engagement.
â€¢	AI Companion Interaction: Leverage OpenAIâ€™s API (GPT-4 or similar) so the ghost can converse naturally with the user. This provides a unique personality to the pet â€“ the ghost can answer questions, tell jokes, or respond to userâ€™s messages in a contextual, human-like way. By integrating OpenAIâ€™s powerful language model, we avoid building an AI from scratch and can easily add natural language chat capabilities[2][3]. The objective is to make the ghost feel like a real companion with a distinct persona (friendly with a playful spooky twist) while ensuring responses are safe and on-theme.
â€¢	Cross-Platform Accessibility: Allow users to access and manage their ghost on multiple platforms â€“ primarily via the immersive iOS app, and alternatively through a web dashboard in any modern browser. A user can feed or chat with their ghost on the phone, then later check on it or continue the conversation from a desktop. All data and state must seamlessly sync in real time between the iOS app and the web app. This ensures a consistent experience and demonstrates the power of a unified backend for cross-platform apps.
â€¢	Real-Time Synchronization: Implement real-time updates so that any change in the ghostâ€™s state (hunger level, mood, name, etc.) is instantly reflected on all clients. For example, if the ghost is fed on the phone, the web dashboard should immediately show the updated hunger level. This is achieved via Supabaseâ€™s realtime service, which can broadcast database changes to connected clients[4]. Real-time sync is crucial for maintaining consistency and also enables dynamic features (like a live status or possibly letting multiple users observe changes, e.g., for a public leaderboard view).
â€¢	Leaderboard & Social Sharing: Provide a public leaderboard of ghosts so users can see how their pet ranks against others. This gamifies the experience â€“ ghosts might be ranked by level, â€œhappinessâ€ or other stats to drive friendly competition. The objective is to foster a community aspect: users can show off their well-kept or high-level ghost, and even view other ghostsâ€™ profiles. (Only non-sensitive info like ghost name, level, and perhaps owner nickname will be shown publicly.) This feature also serves as a showcase of multiple usersâ€™ data and a test of the multi-user capabilities of the app.
â€¢	Leverage AI Development (Kiro): A meta-objective is to utilize Kiroâ€™s AI-powered development environment throughout the project, as encouraged by the hackathon. By using Kiroâ€™s capabilities (spec-driven development, agent hooks, steering documents, and Model Context Protocol), the goal is to accelerate building a robust app despite being a solo developer. Kiro assists from brainstorming to implementation: it handles much of the heavy lifting in code generation so the developer can â€œfocus on the magicâ€[5]. This not only speeds up development within the short hackathon timeframe, but also demonstrates an advanced use of AI in the development process itself (a key judging criterion).
By meeting these objectives, Ghostagotchi aims to deliver a polished, creative blend of AR gaming, pet simulation, and AI companionship. It should highlight the hackathonâ€™s themes by bringing a â€œspookyâ€ virtual friend to life and showing off the integration of multiple cutting-edge technologies into one compelling application.
2. Target Users and Use Cases
Target Users: Ghostagotchi is designed for a tech-savvy and creative audience who enjoy virtual pets, augmented reality games, and AI interactions. Key user groups include:
â€¢	AR Enthusiasts & Mobile Gamers: People who enjoy AR games (like PokÃ©mon GO) or virtual pet games will be drawn to caring for a ghost in their actual environment. The Halloween/spooky theme can attract users who find ghost characters fun or appealing.
â€¢	Fans of Virtual Companions: Users of AI chatbots or virtual friends (e.g., Replika, Tamagotchi fans) who want a more novel character â€“ in this case, a ghost with personality â€“ that they can talk to and receive entertaining responses from.
â€¢	Hackathon Judges & Tech Community: Since this is a hackathon project, judges and fellow developers are a special audience. They will use Ghostagotchi as a demonstration of technical integration and creativity. Theyâ€™ll be looking for how intuitive the app is and how effectively it showcases Kiro and the multi-platform features (as a proof-of-concept for real users beyond the hackathon).
â€¢	Casual Users on Web: People who might not have an AR-capable device or who come across the project online can still engage via the web dashboard, view othersâ€™ ghosts on the leaderboard, and perhaps create their own ghost through a simple web interface.
Use Cases and User Stories: Below are typical scenarios in which a user would interact with Ghostagotchi:
â€¢	U1: First-Time Adoption: A new user downloads the iOS app or visits the web app and creates an account (via email or a social login). They are prompted to â€œadoptâ€ their ghost â€“ giving it a name and perhaps a short greeting. The system creates a new ghost pet for them with initial default stats. The user sees their ghost appear (in AR on iOS, or as an image/avatar on web) and an initial tutorial message from the ghost might welcome them.
â€¢	U2: Daily Care Routine: The user opens the Ghostagotchi app each day to care for their ghost. For example, in the morning they feed the ghost (tapping a feed button or performing an AR interaction like dropping a virtual treat). This increases the ghostâ€™s hunger meter to full and the ghost responds happily. Later, the ghostâ€™s hunger declines over time â€“ if the user checks in the evening, the app might show a notification or the ghost might say â€œIâ€™m feeling hungryâ€¦â€. The user feeds it again or plays a mini-game if implemented. These routine actions keep the ghost â€œaliveâ€ (or as a happy ghost) and help it level up over time.
â€¢	U3: AI Chat Interaction: The user engages in a conversation with their ghost. For example, the user asks, â€œHow are you feeling today?â€ via a text chat interface (or voice input on iOS if available). The app sends this to the OpenAI API and the ghost replies with a personality-filled answer, e.g., â€œIâ€™m a bit bored floating around here. Maybe a snack or a joke would cheer me up!â€ The user can have a back-and-forth chat â€“ asking the ghost for a story, or for advice (the ghost might give playful, spooky-themed responses). This use case provides entertainment and emotional connection, as the ghostâ€™s AI adds unpredictability and charm to the interaction.
â€¢	U4: Cross-Platform Continuity: A user interacts with the ghost on one platform and continues on another seamlessly. For instance, while commuting, the user uses the iOS app to play with the ghost in AR. Later at work, the user opens the web dashboard on their laptop â€“ they can see the ghostâ€™s updated status (e.g., hunger is now 80% after the earlier feeding) and continue the chat conversation from where they left off. The real-time sync ensures that any chat messages or stat changes from the phone are already reflected on the web. This use case highlights the flexibility and ubiquity of the experience â€“ the ghost is â€œalways with you,â€ accessible from any device.
â€¢	U5: Leaderboard Browsing: The user navigates to the global leaderboard (on the web dashboard or via a link in the mobile app). They see a ranked list of user ghosts â€“ for example, showing Ghost Name, Owner (username or initials), Level, and maybe a â€œmoodâ€ or â€œageâ€. The user finds their own ghostâ€™s position and compares stats. They also click on the top-ranked ghost to view its profile (read a short description or last status message). This might motivate the user to take better care of their ghost or interact more (to gain experience points and level up). In some cases, even non-logged-in visitors could view the leaderboard as a demo of the appâ€™s community aspect.
â€¢	U6: Neglect and Notification (Optional): If a user forgets to care for the ghost for a long period, the ghostâ€™s stats (like mood or energy) drop. The system could optionally send a notification or email reminder: â€œYour ghost misses you! ðŸ‘» Itâ€™s feeling very lonely.â€ (Push notifications on iOS or an email via Supabase if configured). When the user returns, the ghost might express sadness via chat (â€œWhere have you been? It got cold in the attic without you!â€) â€“ demonstrating the AIâ€™s ability to use context. This use case ensures re-engagement and also showcases a bit of the ghostâ€™s AI-driven personality reacting to user absence.
â€¢	U7: Development & Showcase: (For the developer/judge perspective) The project repository includes the specification and documentation on how Kiro was used to build Ghostagotchi. A judge or developer might inspect the code and the .kiro directory to see the specs, hooks, and steering files used. They might run the app (web demo link, TestFlight for iOS, or watch the demo video) to evaluate its functionality. This â€œuse caseâ€ ensures that beyond the end-user functionality, the project meets hackathon submission requirements by demonstrating the integration of Kiro in the development process.
In summary, Ghostagotchi serves both entertainment use cases (virtual pet care and AI companionship for users) and technical demonstration use cases (cross-platform sync, AR capabilities, and AI development workflow for the hackathon judges). The design must balance being fun and engaging for users while also clearly showcasing the technical achievements in integration and AI-driven development.
3. Functional Requirements
Ghostagotchi comprises two client applications â€“ an iOS mobile app and a web dashboard â€“ which share common backend functionality. Below, requirements are organized by platform (iOS and Web), followed by any common cross-platform requirements.
3.1 iOS Mobile App (Augmented Reality Ghost Pet)
The iOS application provides an interactive AR experience and core pet management features. All functionality should be accessible after the user has authenticated via Supabase Auth (email/password or social login). The iOS appâ€™s key functional requirements are:
â€¢	User Authentication (iOS): Allow account creation and login using Supabase authentication services. Users can sign up with an email & password or sign in via popular social providers (e.g., Sign in with Apple, Google, etc.). The app should integrate Supabaseâ€™s Auth SDK to handle these flows securely. (Supabase Auth supports multiple methods including password, magic links, OTP, and various social logins[6].) On first launch, if the user is not signed in, present a login screen. Upon successful login or signup, retrieve the userâ€™s profile and proceed to the main app.
â€¢	Ghost Creation & Initialization: For a new user (no existing pet), guide them through creating their ghost. This may include choosing a name for the ghost (required) and perhaps selecting an appearance or type (for now, we assume one default ghost model/appearance). Upon confirmation, the app will create a new pet entry in the database associated with that user. Each user can have at most one ghost pet â€“ enforce this via the data model (unique relation per user). If the user already has a pet record (returning user), skip creation and load that ghostâ€™s data.
â€¢	Augmented Reality Ghost Display: Utilize ARKit to present the ghost in the userâ€™s real-world environment through the device camera. The app must:
â€¢	Access the camera and motion sensors to establish an AR session (world tracking configuration). If needed, request camera permission from the user.
â€¢	Display the ghost as a 3D model or animation in the AR scene. (For example, a semi-transparent cartoon ghost model floating a few feet in front of the user, or anchored to a plane detected by ARKit on the floor/table.) The ghost model could be created with RealityKit or SceneKit and should be rendered with some playful animations (idle floating, waving, etc., to give it life).
â€¢	Allow basic interaction in AR: e.g., the user can tap on the ghost or come closer to trigger a reaction (like the ghost waving or a sound effect). While full gesture interaction is not required, tapping could be used for petting the ghost (increasing its happiness).
â€¢	The AR view should have an overlay UI showing essential info (e.g., ghostâ€™s name and key status bars like hunger or mood). The ghostâ€™s status might also be represented visually (if the ghost is hungry, maybe an icon or its expression shows it).
â€¢	Provide fallback for non-AR mode: If ARKit is not available (older device) or user is in an environment where AR doesnâ€™t work well, the app should still allow interaction via a non-AR view (e.g., displaying the ghost on a plain background or using a 2D ghost illustration). This ensures the app is usable even without perfect AR conditions, though AR is the primary mode.
â€¢	Pet Status Management (iOS): Display and update the ghostâ€™s status indicators â€“ for example:
â€¢	Hunger (or â€œenergyâ€): a value that decreases over time and can be refilled by feeding.
â€¢	Mood/Happiness: a value representing how happy or sad the ghost is. It could be influenced by interactions (chatting might increase it, neglect might decrease it).
â€¢	Level/Experience: the ghost can gain experience points (XP) for positive interactions (each feeding or chat could give some XP), and when XP thresholds are reached, the ghost â€œlevels upâ€. The level could be mostly for bragging rights (used in leaderboards).
â€¢	These stats should be visible in the UI (perhaps as bars or icons). They update in real-time as the user interacts. For instance, feeding fills the hunger bar, and over time the bar ticks down. A â€œheartbeatâ€ timer or background task in the app may decrement hunger/mood periodically (e.g., 1% per hour) when the app is active; when the app is closed, these can be updated next time (based on timestamps in the backend).
â€¢	Feeding Interaction: The user can feed the ghost through the UI. This might be done via:
â€¢	An AR action: e.g., tapping a food button places a virtual treat in AR, and the ghost moves to â€œeatâ€ it.
â€¢	Or a simple button in the overlay (â€œFeedâ€). On tap, the app will update the ghostâ€™s hunger in the database (set to 100% or increase it) and maybe also increase XP. The ghostâ€™s model might play a happy animation (spin or smile).
â€¢	The feed action should be rate-limited (e.g., feeding only has an effect if the ghost is not already full or not fed in the last X minutes) to prevent spamming. The app can enforce this by checking the ghostâ€™s lastFed timestamp or current hunger level.
â€¢	After feeding, the updated hunger value is saved to Supabase and broadcast to other clients in real-time.
â€¢	Play/Interaction for Mood: (Optional/minimal implementation) The user should have a way to increase the ghostâ€™s happiness aside from feeding, e.g., â€œPlayâ€ with the ghost:
â€¢	This could be a simple action like a â€œPlayâ€ button that triggers an animation (the ghost tells a joke or does a trick) and boosts the mood stat.
â€¢	Or it could be more involved (a mini-game or petting via AR tap). Given hackathon scope, a button triggering a fun ghost animation and mood increase is sufficient.
â€¢	This action updates the mood stat (and possibly XP) in the database.
â€¢	AI Chat Conversation (iOS): The user can chat with the ghost using natural language:
â€¢	Provide a chat UI, for example a text input field (perhaps appearing when the user swipes up or taps a â€œChatâ€ button on the AR screen, pausing the AR scene in the background).
â€¢	The user enters a message or question for the ghost. When submitted, the app calls the backend API (or directly the OpenAI API via a secure function) to generate the ghostâ€™s reply. A loading indicator should show while the ghost â€œthinksâ€.
â€¢	Once a response is received, display it as a chat bubble or an overlay text in the AR scene near the ghost. Optionally, use text-to-speech to have the ghost speak the answer in a ghostly voice for immersion (if time permits and it fits device capabilities).
â€¢	The ghostâ€™s responses should stay in character â€“ e.g., a friendly ghost that might use spooky puns occasionally. A predefined system prompt will be used on the API to establish this persona.
â€¢	The conversation context: the app could include recent messages for context so the ghost remembers the last question. At minimum, send the last user message; at best, maintain a short history (last 2-3 exchanges) in the prompt for continuity. (For longer-term memory, see â€œdata schemaâ€ about storing chat logs).
â€¢	Ensure each message (user and ghost) is also stored in the local UI state or a chat log so the user can scroll through the conversation. This history might reset if the session restarts, unless persistent storage is implemented.
â€¢	OpenAI API Integration: The app will use OpenAIâ€™s chat completion API through a cloud function or via the Next.js backend. The iOS app should not contain the API key. Instead, it will call a secure endpoint (e.g., POST /api/chat) with the user message. The server will append the ghostâ€™s persona prompt and call OpenAIâ€™s API. The ghostâ€™s reply is then returned to the app. This keeps the API key secure and allows monitoring usage. The result is a fluent AI chat experience for the user, powered by a state-of-the-art model (like GPT-4, known for its conversational ability[3]).
â€¢	If the OpenAI API call fails (network or rate-limit), handle it gracefully (e.g., ghost says â€œ... I suddenly lost my voice, can you repeat that?â€ or an error message).
â€¢	Real-Time Data Sync (iOS): The iOS app must subscribe to relevant realtime channels so that it updates the UI when changes occur elsewhere:
â€¢	Use Supabase Realtime to listen for updates to the petâ€™s data (e.g., the pets table row for this userâ€™s ghost). Supabaseâ€™s Swift SDK or realtime client will be set up to listen to Postgres changes[4].
â€¢	When a change is detected (for example, if the userâ€™s ghost was fed from the web dashboard or some stat changed), the app should immediately reflect that â€“ update the displayed hunger, mood, level, etc. This keeps the iOS view in sync with any external updates.
â€¢	Also listen for inserts in a chat_messages table if chat history is shared across devices (so that a conversation started on web is visible on mobile, etc.).
â€¢	The realtime system should ideally use a lightweight mechanism (Supabase uses web sockets under the hood) and not poll frequently to save battery.
â€¢	Leaderboard Access (iOS): Provide a way for the iOS user to view the global leaderboard of ghosts:
â€¢	This could be a simple WebView embedded in the app that loads the leaderboard from the Next.js web (to save time on implementing a separate UI). For example, a â€œLeaderboardâ€ button in the app could open an in-app browser showing the /leaderboard page from the web app.
â€¢	Alternatively, implement a native screen: a table view of top ghosts with rank, ghost name, level, and maybe owner name. This would require an API call to fetch leaderboard data. If time is limited, the WebView approach is acceptable (leveraging the already-built web component).
â€¢	Leaderboard is read-only from the app (just viewing), with potential future expansion to allow interacting with other ghosts (out of scope for now).
â€¢	Settings/Profile (iOS): Basic settings like log out, and possibly editing the userâ€™s profile:
â€¢	The user should be able to log out from the app (clearing session and returning to login screen).
â€¢	If a profile exists (display name or avatar), allow updating it. At minimum, let the user change their ghostâ€™s name (in case they want to rename the pet). Renaming the ghost would update the pet record in DB and reflect on other platforms and the leaderboard.
â€¢	Optionally, allow toggling notification settings (if we implement reminders).
â€¢	Error Handling and Feedback: The app should handle failure cases gracefully:
â€¢	If the Supabase auth token expires or network is down, prompt for re-login or show a message.
â€¢	If a database update fails (e.g., feed action doesnâ€™t persist), inform the user to retry.
â€¢	Use alerts or toast messages for feedback like â€œGhost fed!â€ or errors like â€œCouldnâ€™t reach the server, please check connection.â€
â€¢	Performance: Ensure the AR experience runs smoothly (target 30/60 FPS in AR if possible) and that realtime updates or data fetches do not stall the UI. Use background threads for network calls and keep AR rendering on the main thread optimized (limit number of AR anchors or animations to maintain performance on mobile devices).
3.2 Web Dashboard (Next.js Web App)
The web application allows users to manage and interact with their ghost from any browser, and provides public-facing pages (like the leaderboard). Built with Next.js (React and Node.js), it will support both client-side interactive features and server-side functionality (API routes for backend logic). Key functional requirements for the web dashboard:
â€¢	User Authentication (Web): Integrate Supabase Auth in the web app for login and signup:
â€¢	Provide a responsive login page where users can sign in with email/password or click to authenticate via social providers (Google, GitHub, etc., as enabled in Supabase). The Next.js app can use the Supabase JavaScript client (@supabase/supabase-js) to handle the OAuth flows or magic link if needed.
â€¢	Ensure proper handling of authentication tokens (Supabase returns a JWT for the user). On successful login, store the session (e.g., in cookies or local storage via supabase client) and redirect to the main dashboard.
â€¢	Support password reset or email verification flows if time permits (Supabase can send magic link emails by default, which we can enable in the project settings).
â€¢	Like the iOS app, only authenticated users can access their ghostâ€™s dashboard. Implement route protection so that hitting the dashboard without a session redirects to login.
â€¢	Ghost Dashboard View: After login, the user sees the main dashboard page. This page should present:
â€¢	The ghostâ€™s name and avatar. Since web canâ€™t easily render the 3D AR ghost, we will show a representation: possibly a static image or an animated GIF of the ghost. (We could pre-render a few ghost expressions or use a simple CSS animation to make it float).
â€¢	The ghostâ€™s key status bars/metrics (hunger, mood, level, etc.), similar to the mobile UI. These should update in real time if changes occur. For example, if the ghostâ€™s hunger is 50%, show a half-filled bar or a numeric value.
â€¢	Actions the user can take: â€œFeedâ€ button, â€œPlayâ€ button, and a chat interface. These controls on the web will mirror the iOS functionality:
o	Clicking Feed will trigger a function (probably via an API call or direct Supabase update) to refill the hunger and update stats. Immediately update the UI optimistically and rely on realtime for final state, or wait for confirmation. Possibly disable the feed button if the ghost is already full or implement a cool-down as on iOS.
o	Clicking Play (if implemented for mood) does similar for mood stat.
o	The Chat interface on web can be a chatbox component. The user can type a message in a text input and submit. Display the userâ€™s message in a chat log area, call the backend (Next.js API route) to get the ghostâ€™s reply, then display the ghostâ€™s reply. The chat log on web should accumulate messages so the user can scroll up to see past conversation in this session.
o	Optionally, allow pressing Enter to submit and basic UI niceties like disabled input while waiting for response.
o	The Next.js API handling the chat will be the same that the iOS app uses, ensuring consistency.
o	Security: ensure the API route verifies the userâ€™s identity (via Supabase JWT or session) so one user cannot chat as anotherâ€™s ghost. The server can infer the user from the session and fetch that userâ€™s ghost to construct the AI prompt.
â€¢	The dashboard should poll or subscribe for ghost state changes. We will set up Supabase Realtime subscription in the React client to listen for changes to the userâ€™s pet record (e.g., if pets.hunger or pets.mood changes). On receiving an update, the React state should update the displayed values immediately. This way, if the iOS app or another session updates something, the web reflects it live.
â€¢	Possibly use a useEffect hook to subscribe to the realtime channel on component mount, and remember to unsubscribe on unmount.
â€¢	Public Leaderboard Page: Implement a leaderboard at ~/leaderboard route that is publicly accessible (no auth required to view). Features:
â€¢	It lists the top N ghosts (e.g., top 10 or 20) sorted by a certain metric, likely the ghostâ€™s level or total experience points. (Level provides a clear ranking; if there are ties, we can then sort by XP or by who reached first via creation date).
â€¢	For each entry, display: Rank #, Ghost Name, Level, and perhaps Owner name or username. We must be mindful of privacy â€“ since this is public, we should not display personal info like full email. Instead, if a user profile has a nickname or just display partial email (e.g., â€œalice***@gmail.comâ€) or a generic identifier. We can also choose to just display ghost names to keep it simple (assuming ghost names tend to be unique/fun).
â€¢	This page should fetch data from the backend: possibly create a Supabase RPC or REST endpoint (like a stored procedure or a serverless function) to get the top records. Or simply use the Supabase JS client on the front-end to query pets table ordering by level and limiting to 10, since the table is public read for this purpose (or implement an RLS policy to allow reading certain fields of othersâ€™ pets for leaderboard). To keep it simple and secure, we might implement an API route in Next.js (e.g., GET /api/leaderboard) that performs a database query (using Prisma or Supabase client with admin rights) and returns the data.
â€¢	The leaderboard should update periodically or in real-time. We could subscribe to changes on the pets table for high-level events. However, getting real-time updates for potentially many records might be overkill. Instead, a simple periodic refresh (like refresh the list every 30 seconds) or just page refresh might suffice for hack demo. If using realtime, we might subscribe to all pets changes and maintain a local sorted state (only practical if few users; with many itâ€™s heavy, so likely weâ€™ll do a single fetch on page load).
â€¢	Each entry could link to a Ghost detail page (optional) showing more about that ghost (like a profile: ghostâ€™s age, maybe last message, ownerâ€™s join date, etc.). This would be nice but is not strictly required. For the hack we might omit individual pages and just show the list.
â€¢	Profile Management (Web): Provide a page or modal for the userâ€™s profile if needed:
â€¢	Allow the user to set or change a display name (to be used on the leaderboard). If not implementing a separate profile table, we might use the ghostâ€™s name as the display name on leaderboard, or simply not show user name. However, ideally each user has a profile with a username. The web app could have an Account Settings page where the user enters a preferred nickname. This updates the profiles table (or equivalent) in the database.
â€¢	Also possibly allow ghost renaming here (if not in main dashboard). Or a button â€œRename Ghostâ€ that updates the petâ€™s name.
â€¢	The profile page can also show account info like the linked email (from Supabase auth) and allow log out.
â€¢	Logout (Web): The user should be able to log out (e.g., a logout button in a menu or profile dropdown). Clicking it will clear the Supabase auth session (via SDK) and redirect to the login page. Also ensure any realtime subscriptions are cleaned up.
â€¢	Responsive Design: The web dashboard should be mobile-friendly as well, in case users access it on a phone. Use responsive layouts (CSS flex/grid, or a UI library) so that the main dashboard and leaderboard are usable on smaller screens. This isnâ€™t the primary use (since we have native mobile app), but itâ€™s good practice and allows accessibility for those without iOS devices (e.g., Android users can still use the web).
â€¢	Server-Side Rendering / SEO: The Next.js app can server-render some pages:
â€¢	The login page and leaderboard page can be server-side rendered for faster first load and SEO (especially for the public leaderboard, which might be indexed on the hack submission page).
â€¢	The leaderboard data could be loaded in getServerSideProps so itâ€™s ready on first render. However, given it might change frequently, we might also just fetch on client.
â€¢	If a Ghost detail page exists, it could be statically generated or SSR with the ghostâ€™s info. This could be a stretch goal.
â€¢	API Endpoints (Web/Backend): The Next.js app will implement certain API routes (under /pages/api/* or as serverless functions) to handle functionality that should not be done on the client (such as OpenAI calls, or complex multi-step updates). The required endpoints will be detailed in section 7, but functionally from the web app perspective:
â€¢	The web UI will call POST /api/chat when the user sends a message, rather than calling OpenAI directly from the browser.
â€¢	The web UI might call POST /api/feed or similar when user clicks Feed, or it could directly use the Supabase JS client to update the database (which might be simpler for something straightforward like feed action). We will decide to possibly use direct Supabase client for basic DB ops and use API routes for more secure or complex operations (like chat or maybe a combined action).
â€¢	Real-Time Sync (Web): As mentioned, the web uses Supabase Realtime subscription to get updates:
â€¢	For the userâ€™s own ghost data: subscribe to the specific row or use a filter on the pets table for user_id = currentUser. Supabase allows filtering realtime events by criteria on the payload.
â€¢	Ensure that when an event comes (e.g., hunger updated), the UI state is updated. If the user is in the middle of something (like typing a chat), handle UI carefully (maybe donâ€™t disrupt an ongoing input, but do update stats).
â€¢	If implementing presence (not required, but possible via Supabase Presence feature), we could show if the userâ€™s session on another device is online. For example, if the user is currently also logged in via iOS, we could reflect that. This is a nice-to-have: Supabase presence could track connections by user. We do not strictly need it, but itâ€™s an available real-time feature[7].
â€¢	Web Performance and Security:
â€¢	The web app should load quickly and minimize data transfer. Use efficient querying (only necessary fields from the DB) and perhaps caching for data that doesnâ€™t change often (like once loaded ghost stats until change events).
â€¢	Implement Row-Level Security (RLS) on the database to ensure users can only read/write their own data from the client. We will have RLS policies such that, for example, a user can only select or update on the pets table where user_id = auth.uid(). This way, even if the Supabase client is used directly in the browser, other data is protected by the backend.
â€¢	For any admin-level queries (like assembling the global leaderboard which reads many users), the Next.js API route will use a service role key or our Prisma connection (with proper privileges) so that it can bypass RLS for that specific safe operation.
â€¢	Prevent XSS and injection by sanitizing any user-input that might be displayed (though in our app, most input is just chat to OpenAI, which doesnâ€™t get shown to other users except possibly if we had some global feed, which we do not).
â€¢	Use HTTPS for all network calls (the app will be deployed presumably on secure domains; Supabase endpoints are HTTPS).
â€¢	Analytics and Logging (Optional): If time permits, integrate simple logging (maybe just browser console or Supabase logs for function calls) to monitor usage. This can help in debugging during development and ensuring chat requests etc., are functioning when multiple users test it.
3.x Cross-Platform and Common Requirements
(Note: These requirements are inherently covered above in each platformâ€™s context, but we highlight them here for completeness.)
â€¢	Unified Backend State: Both the iOS and Web clients operate on the same single source of truth (the Supabase Postgres database). Any change to the ghostâ€™s state (feeding, stat changes, naming, etc.) must be written to the database, and both clients should read from and subscribe to that database. This ensures consistency â€“ the ghostâ€™s data is not stored locally in a divergent way. The requirement is that at app startup (on any platform), the app fetches the latest ghost data from the DB and then continues to sync.
â€¢	Real-Time Cross-Platform Synchronization: As described, the system shall propagate updates in real-time. This means using Supabase Realtimeâ€™s Postgres Changes feature to subscribe to specific tables/events[8]. The functional result is that a user can have the web dashboard open and the iOS app simultaneously, perform an action on one, and see the effect on the other within a second or two. This is a core functional requirement to demonstrate the effectiveness of the stack (without requiring manual refresh).
â€¢	Consistent Ghost Logic: The rules for how the ghostâ€™s stats change, how XP is calculated, etc., should be the same on both platforms:
â€¢	For example, if feeding gives +10 XP and sets hunger to 100, that logic should be applied regardless of whether the feed action came from iOS or Web. We will likely centralize such logic on the backend (either in a database function or in the Next.js API route). Alternatively, ensure both clients implement it identically if done client-side. Consistency is key to avoid one platform doing something the other doesnâ€™t.
â€¢	Data Validation: The system should enforce valid ranges and rules for ghost data:
â€¢	Hunger and mood should be kept within 0-100%. If a client tries to set beyond that, the backend or database should clamp it.
â€¢	XP should only increment forward, level should only increase when thresholds passed, etc. If using a backend function to handle leveling up (like if XP > threshold then level++), that should be triggered centrally. Possibly use a database trigger or handle in application code.
â€¢	Each user only has one pet: enforce via unique constraint or check on creation (attempt to create a second pet for same user either fails or replaces the existing â€“ we will likely prevent creation if one exists).
â€¢	Scalability of Multi-User: While initially each ghost is only interacted with by its owner, the design anticipates potentially many users each with their own ghost. The realtime architecture should scale to many concurrent clients without data mixing. Supabaseâ€™s channels are typically based on table or user-specific subscriptions. We will ensure each client only subscribes to relevant data (e.g., their own ghostâ€™s row changes, or global changes that matter).
â€¢	Internationalization (Future): The appâ€™s text and ghostâ€™s communications will be in English for the hackathon. We note that future versions might consider localization (given ghosts could speak any language via AI). But currently not in scope to implement multiple languages beyond possibly the ghost responding in the userâ€™s language if prompted.
In summary, the functional requirements ensure that on iOS, users get an immersive AR pet experience, and on web, they get a convenient dashboard, with both offering the core pet care and AI chat features. The two platforms are fully interoperable through a shared backend and real-time updates. This satisfies the requirement of stitching together multiple technologies â€“ AR, web, mobile, real-time DB, and AI â€“ into one harmonious application.
4. Non-Functional Requirements
In addition to the features above, Ghostagotchi must meet several non-functional requirements, covering performance, security, usability, and other quality attributes:
â€¢	Performance & Responsiveness: The app should provide a smooth interactive experience:
â€¢	Mobile Performance: The AR rendering on iOS should maintain an acceptable frame rate (target 30 FPS or better) so that the ghostâ€™s animation and movement appear smooth. UI interactions (button taps, chat input) should feel instant â€“ network calls (like feed or chat) should be done asynchronously so the UI isnâ€™t blocked. Use loading indicators for any operations that take more than ~500ms (chat likely will, due to API call latency).
â€¢	Web Performance: The web dashboard should load in a few seconds on a typical connection. Use SSR where appropriate to improve perceived performance. Interactive updates (like stat changes via realtime) should reflect within <1 second of the DB update (Supabase realtime latency is typically very low, suitable for games and live apps[9]). The web UI should also remain responsive during chat calls â€“ possibly by streaming the response (if using OpenAIâ€™s streaming) or at least showing a typing indicator.
â€¢	The system should handle moderate concurrency (for hackathon demo, maybe dozens of users). Supabase can handle multiple simultaneous connections for realtime and queries; OpenAI API calls will be rate-limited by our account, but our usage will be low volume (we might add a small delay or limit on user message frequency to avoid spamming the API).
â€¢	Scalability: Although the user base initially is small (hackathon judges, a few testers), the architecture should conceptually scale:
â€¢	The backend (Supabase Postgres) should be able to scale to many users/pets. All data operations are fairly lightweight (some row updates, selects). Supabaseâ€™s managed Postgres can be scaled vertically if needed. Prisma and Next.js serverless functions can handle increased load by horizontal scaling (especially if hosted on Vercel).
â€¢	The real-time feature uses websockets; for thousands of concurrent users, Supabase realtime will distribute the load (itâ€™s built on a dedicated Elixir server). In our scope, we likely wonâ€™t hit limits.
â€¢	If usage grew, weâ€™d consider partitioning heavy operations (for example, moving AI calls to background jobs if needed). But for now, each AI call is on-demand and synchronous to the user action.
â€¢	Security & Privacy:
â€¢	Authentication & Authorization: Enforce secure access using Supabase Auth tokens. All client-server communication should include the userâ€™s JWT (automatically done via Supabase client or via Authorization headers on our API routes). The databaseâ€™s Row-Level Security ensures each user can only modify their own records[10][11]. Any attempts to bypass the client and call the endpoints directly with invalid credentials should be rejected (e.g., Next.js API will check for a valid session or require a service key for certain operations).
â€¢	Sensitive Data: Limit what data is exposed. We do not store highly sensitive personal info (just email and perhaps a nickname). Even so, protect email addresses â€“ e.g., the leaderboard will not display full emails, and the database will not allow one user to read anotherâ€™s email due to RLS. Passwords are never stored by us (Supabase manages them securely with bcrypt on the auth server).
â€¢	API Security: The OpenAI API key is kept on the server side only. We use environment variables on the Next.js server (or a Supabase Function secret) to store it. The client never sees the key. We may implement basic rate limiting on our chat endpoint to prevent abuse (for instance, a user can only send a new message once the previous response is received, etc., and maybe a hard cap like 5 messages per minute to control cost).
â€¢	Network Security: Use TLS/HTTPS for all communications. Both the Next.js app and Supabase endpoints are HTTPS. We will ensure no mixed content or insecure requests.
â€¢	Secure Storage: Data is stored in Postgres which is on a secure cloud instance. Supabase provides automatic backups and encryption at rest. The Prisma connection to the DB will use a secure connection string as provided by Supabase.
â€¢	Privacy of AI Interactions: User conversations with the ghost are sent to OpenAIâ€™s servers. We should mention in documentation that those are processed by OpenAI (which has its own data policies). If this were a production app, weâ€™d need user consent for AI processing. For the hackathon, itâ€™s implicit in functionality.
â€¢	Content Filtering: The ghostâ€™s AI should avoid inappropriate or harmful content. We will provide a system prompt that the ghost is friendly and follows OpenAI content guidelines. Optionally, we could utilize OpenAIâ€™s moderation API to screen user inputs or AI outputs, but due to time we may rely on the modelâ€™s own filtering. Non-functional requirement is that the ghost never produces disallowed content (hate, extreme violence, etc.), keeping the experience family-friendly. In testing, if we find any concerning outputs, weâ€™ll adjust the prompt or user instructions to mitigate that.
â€¢	Usability & UX:
â€¢	Simplicity: The app should be intuitive. Even without a detailed tutorial, a user should grasp that they have a pet ghost, see its needs, and see obvious buttons to interact (feed, chat, etc.). Use recognizable icons (e.g., a food icon on the feed button, a chat bubble icon for conversation).
â€¢	Feedback: Provide immediate visual or audio feedback when actions occur. For example, when feeding, animate the ghost or show a snack icon briefly, play a munch sound; when mood increases, maybe a happy ghost animation or sparkle effect. On web, use simple animations (like fading in updated values or a quick highlight of the bar).
â€¢	Consistency: Ensure the branding and theme are consistent. Likely weâ€™ll use a spooky/cute theme â€“ dark mode UI with Halloween colors (purple, orange, black) as per hackathon spirit. The ghost character design should be consistent between AR and web (if the web uses an image of the ghost, use a render or illustration that matches the AR model).
â€¢	Accessibility: Consider basic accessibility â€“ e.g., on iOS, support VoiceOver for key UI elements (labels on buttons: â€œFeed ghostâ€ etc.). On web, ensure proper alt text for images (ghost avatar) and semantic HTML for forms. Color choices should have sufficient contrast for readability (especially since likely dark background).
â€¢	Error messages: If something goes wrong (like failed login, server error on chat), display a user-friendly message (â€œOops, the ghost is sleeping. Please try again in a moment.â€) rather than a cryptic error. This keeps the experience within the fun narrative.
â€¢	Reliability & Availability:
â€¢	The app should handle network disruptions gracefully. If the user is offline:
o	The iOS app could detect no internet and perhaps allow limited offline interaction (the ghost could have a canned response or the AR view still works but actions canâ€™t be saved). However, since core features (auth, DB, AI) need connectivity, we will mainly display an â€œOffline â€“ please check your internetâ€ message and disable actions that require network.
o	If a realtime update is missed or delayed, the system should recover when connectivity returns (Supabase realtime will automatically catch up states or the app can re-fetch critical data on resume).
â€¢	The backend services (Supabase and OpenAI) are managed by third parties with high uptime, but we should anticipate brief downtimes:
o	If Supabase is down, users cannot log in or load data â€“ show a message accordingly.
o	If OpenAI is down or returns an error, the ghost can reply with a default apology or fallback message from a small local list (to not leave the user hanging).
â€¢	Use transactional updates where needed. For example, if feeding increases both hunger and XP, ensure both are updated together. Possibly do this via a single SQL update or within a transaction (Prisma can handle transactions if needed). This prevents state mismatch (like hunger updated but XP not due to an error).
â€¢	Maintainability & Extensibility:
â€¢	The codebase should be organized clearly:
o	The Prisma schema and Next.js backend logic should be modular (separate modules for pet management, chat, etc.).
o	The iOS code should follow a pattern (MVC or MVVM) to separate AR view, state management, and network calls. This makes it easier to extend (e.g., adding new actions, or new UI screens).
â€¢	Add comments and documentation especially in the .kiro spec files and README, so future developers (or judges reviewing code) can understand the design and any trade-offs.
â€¢	We plan usage of Kiro spec-driven development, which inherently produces a spec that doubles as documentation. Maintaining that spec up-to-date as features change will ensure the code and requirements donâ€™t diverge.
â€¢	The system should be built with future enhancements in mind:
o	e.g., we mention ideas like multiple ghost types, mini-games, social interactions between ghosts. The architecture (with a central DB and real-time updates) can support those with additional tables or logic. The SRS is written comprehensively so that adding features can follow the same patterns (update DB, sync, etc.).
â€¢	Use environment configuration for things like API keys, and avoid hard-coding values. This makes the deployment to different environments (dev, prod) simpler.
â€¢	Compatibility:
â€¢	iOS: The app will target iOS 17+ (or at least iOS 15+ if ARKit features allow) and run on iPhone devices that support ARKit (most models from iPhone 6s/SE (2016) upwards support basic ARKit, but full AR experiences work best on newer devices). It should also run on iPad (if we choose to allow iPad, ARKit works on iPad Pro, etc., though UI might not be optimized for tablet but it should still function).
â€¢	Web: The web dashboard should work on latest versions of major browsers: Chrome, Firefox, Safari, Edge. We will test on Chrome and Safari (especially Safari for compatibility with iOS devices that might use the web). Since we use Next.js and React, it should be broadly compatible; just ensure not to use any bleeding-edge web APIs that arenâ€™t widely supported.
â€¢	Screen sizes: The UI should handle different screen sizes: for AR on smaller iPhones, keep overlays minimal; on larger iPhones or iPads, maybe not full-screen stretched UI (maybe center content). On web, we already plan responsive design for mobile vs desktop.
â€¢	Resource Usage:
â€¢	The app should manage battery and data usage reasonably:
o	AR apps can be battery-intensive; we will use AR features efficiently (pause the AR session when app is backgrounded, etc.).
o	Realtime connections and frequent updates can also use battery â€“ we will subscribe only to necessary events and perhaps throttle updates if they are very frequent (not likely here).
o	Data: Chat responses from OpenAI can be a few hundred tokens at most per reply; this is small per message. The 3D ghost model might be the largest asset â€“ we should optimize its size (e.g., use a lightweight USDZ or RealityKit asset, maybe <5 MB).
o	Supabase calls are lightweight JSON; we should avoid any heavy data transfers (no huge images or files in our scope except maybe the ghost model which is packaged in app).
â€¢	Testing & Accuracy: (More details in section 11, but as a requirement:)
â€¢	The ghostâ€™s stat mechanics should be accurate and bug-free (e.g., feeding always sets hunger to exactly 100 or a defined max, not above; level-ups occur at correct XP thresholds, etc.). We will validate these through unit tests or manual testing.
â€¢	The AR positioning should be reasonably accurate â€“ ghost should appear anchored stably in the environment (this depends on ARKitâ€™s tracking; weâ€™ll use plane detection or fixed anchor to ensure ghost isnâ€™t jittery).
â€¢	The AIâ€™s answers should be contextually appropriate. We should test some sample conversations to tweak the prompt until we consistently get the ghosty persona and no unwanted tangents.
Overall, the non-functional requirements ensure Ghostagotchi is not only feature-rich but also reliable, secure, and user-friendly. The application should feel polished and professional despite being a hackathon project, which will underscore the effectiveness of using Kiro and a solid tech stack to build a complex app quickly. Special attention will be paid to real-time performance, security (auth/RLS), and the quality of the AI interaction, as these are critical to the appâ€™s success and impression on users.
5. UI/UX Design and Major Components
Ghostagotchiâ€™s user experience is designed to be engaging, intuitive, and consistent across platforms. This section describes the major UI components and the user flow on both iOS and Web, highlighting how users will interact with the ghost and navigate the app.
5.1 iOS App UI/UX Flow
On the iOS side, the focus is on an immersive AR experience combined with an overlay of controls. The main screens/components and flow are:
â€¢	Launch & Authentication: When the app launches, it displays a splash screen with the Ghostagotchi logo (perhaps a cute ghost icon with the app name). If the user isnâ€™t logged in, the app presents a Login/Signup screen. This screen uses a simple design: app name/title at top, input fields for email and password, and buttons for â€œLoginâ€ and â€œSign Upâ€ (and possibly â€œContinue with Apple/Googleâ€ for social login). The theme here aligns with the spooky aesthetic (e.g., a dark background with ghostly illustrations, but minimal to keep focus on logging in). After successful login, the user transitions into the main app.
â€¢	Ghost AR View (Home Screen): This is the primary screen once logged in. Itâ€™s an AR camera view occupying the full screen. Overlaid on this AR scene are UI elements:
â€¢	A Ghost 3D model floating in the center (the actual position can be anchored a fixed distance in front of the userâ€™s device initially). The ghost might have a default idle animation (slowly bobbing up and down as if itâ€™s hovering).
â€¢	At the top, the ghostâ€™s Name is displayed (e.g., â€œSpookybooâ€ if the user named it that) in a stylized font.
â€¢	In a corner or along the top, small status icons or bars show Hunger and Mood. For example, a ðŸŽ icon with a bar for hunger, and a ðŸ˜Š icon with a bar for mood. Alternatively, these could be shown when needed (like a button to toggle status display, but always visible is more straightforward).
â€¢	Action Buttons: Overlaid near the bottom of the screen are primary interaction buttons:
o	a Feed button (with an icon of food, say a ghostly cookie or a candy since itâ€™s ghost-themed; could be labeled â€œFeedâ€).
o	a Play button (with a toy icon or a smiley, labeled â€œPlayâ€ or â€œPetâ€).
o	a Chat button (chat bubble icon).
o	Possibly these are in a semi-transparent panel or just floating buttons. For ease, a bottom toolbar with these icons and labels could work (with a translucent dark background).
â€¢	Tapping Feed triggers an animation: e.g., an apple or candy appears in AR, the ghost moves or a small animation of the ghost â€œeatingâ€ plays (like it could spin happily or make a small munch sound). At the same time, the hunger bar fills up (smooth animation from previous value to 100%). A subtle confirmation text like â€œ+10 Hungerâ€ or â€œFed!â€ might briefly appear. This feedback assures the user their action succeeded.
â€¢	Tapping Play could trigger the ghost to do a flip or a dance, and the mood bar increases with a â€œ+15 Moodâ€ indicator briefly. The ghost might emit a playful sound or laugh to show happiness.
â€¢	Tapping Chat opens the chat interface (see next point).
â€¢	Navigation: If we have additional screens like Profile or Leaderboard, there might be a hamburger menu or profile icon at the top corner. For instance, top-left could be a menu icon that slides out a side menu with options: â€œLeaderboardâ€, â€œSettingsâ€, â€œLogoutâ€. Or top-right a profile avatar icon for account options. Given a small app, a single menu button might suffice to access those.
â€¢	Chat Interface (iOS): When the user wants to chat:
â€¢	On tapping the Chat button, the AR view could pause (or continue running in background but dimmed). We show a chat panel covering part of the screen (for example, the bottom half slides up with a chat log and input).
â€¢	The chat panel shows a scrollable area of the conversation history (with the most recent messages at bottom). Each message is in a bubble: user messages aligned to right, ghostâ€™s messages aligned to left, each with different bubble color (maybe userâ€™s in grey or blue, ghostâ€™s in a spooky white or green bubble). We can prefix ghost messages with a small ghost icon avatar for clarity.
â€¢	At the bottom of this panel is a text field with placeholder â€œSay something to your ghost...â€ and a send button (paper plane icon).
â€¢	The user types e.g. â€œHow do you feel?â€ and hits send. The message immediately appears in their bubble (perhaps slightly lighter color until actually processed, to indicate sending). The app calls the API; while waiting, we could show â€œGhostagotchi is typing...â€ or a small loading spinner in the ghostâ€™s bubble area.
â€¢	Once the response arrives, it is displayed in a ghost bubble, possibly along with an animation on the ghost model in the AR background (like the ghost might wave or change expression when speaking). If TTS is enabled, the ghost could speak the message as well.
â€¢	The user can then continue sending more messages. The UI should allow closing the chat (maybe a close â€œXâ€ button on the chat panel) to return to full AR view.
â€¢	The transition between AR and chat should be smooth, perhaps with a little delay or visual effect to maintain immersion (e.g., blur the AR background when chat is open).
â€¢	Leaderboard on iOS: If implemented natively or via webview:
â€¢	From the menu, selecting Leaderboard either opens an embedded WebView of the leaderboard page or navigates to a native screen. If native: it would be a table list of entries (rank 1,2,3,...). This screen likely has a back button to return to the AR view. If using WebView, we would present it modally or push it on a navigation stack.
â€¢	The styling should match the webâ€™s leaderboard style (which weâ€™ll design in web section), but within the app we can add a native header â€œLeaderboardâ€.
â€¢	Settings/Profile (iOS): Possibly accessible from menu:
â€¢	Could include toggles (like enable/disable sound, AR tips on/off) and account options. Minimal need due to hack scope.
â€¢	The user might see their account email and can log out from here (with a confirmation alert).
â€¢	If profile editing is allowed, fields to update display name could be here.
â€¢	Visual Design Elements: The overall look on iOS:
â€¢	Predominantly dark mode (since code-in-dark-mode hackathon theme and suits ghost theme). Backgrounds in AR view are the real world, but UI overlays should be translucent black/grey with white or neon text accents.
â€¢	Use a fun ghost emblem for the app icon and possibly for loading indicators (e.g., a ghost icon bouncing when waiting for response).
â€¢	Animations are used to make the ghost feel alive: subtle idle motions, reaction animations on feed/play, maybe the ghostâ€™s face (if it has eyes/mouth) changes with mood.
â€¢	Sounds (if time): a short ghost â€œwooâ€ sound when happy, a munch sound on feed, etc., to enrich feedback.
â€¢	Error/Status Indicators: If the app is offline or syncing:
â€¢	Show a small banner â€œConnecting...â€ or a chain/broken icon if realtime disconnects.
â€¢	If the ghostâ€™s data is out of date, maybe pulse the status bar until refreshed.
â€¢	Any significant error (like failed to load ghost data on login) should prompt the user with a retry dialog.
User Flow on iOS (Summary): Launch app â†’ Login â†’ (If new) Adopt ghost (name it) â†’ See ghost in AR home screen â†’ Interact via feed/play or open chat â†’ Possibly check leaderboard or settings â†’ Continue recurring usage. The AR home screen is the hub; user generally returns there after any other screen.
5.2 Web Dashboard UI/UX Design
The web app offers a dashboard-style interface. It should be accessible and straightforward, given it runs on varied devices (desktop, tablet, mobile). Major UI components and pages:
â€¢	Landing/Login Page: At the root or when not logged in, the user sees either a landing page with app info or directly a login form. For a quick hack, we might direct to login immediately:
â€¢	A centered login box with â€œWelcome to Ghostagotchiâ€ title and the same login options as iOS (email/password, social login buttons).
â€¢	Possibly a graphic/logo (e.g., ghost icon) to add visual appeal.
â€¢	If a separate landing page exists: it could have a brief tagline (â€œAdopt and chat with your own AI ghost pet!â€) and a prominent â€œGet Startedâ€ / â€œLoginâ€ button.
â€¢	The design is mobile-responsive: on desktop, the login form might be to the right of an illustration (like ghost image), on mobile itâ€™s just a single column form.
â€¢	Main Dashboard (after login): Once logged in, the user is taken to their Ghost Dashboard page (likely the /dashboard or homepage for authenticated user).
â€¢	Header/Nav: A top navigation bar with the app name or logo, and maybe a dropdown showing the userâ€™s name/email with options to Logout or to go to Profile/Settings. Also a nav link to â€œLeaderboardâ€ if appropriate.
â€¢	The main content area might use a two-column responsive layout:
o	The left (or top on mobile) section shows the Ghost Card â€“ containing ghostâ€™s avatar and stats.
o	The right (or bottom on mobile) section is the Interaction Panel â€“ containing feed/play buttons and the chat interface.
â€¢	Ghost Card Panel: This component includes:
o	A ghost image or canvas: possibly show a static 2D ghost illustration or a generated image representing the ghost. (If possible, we could use a GIF of an animated ghost or even a simple WebGL scene for fun, but likely a static image due to time.)
o	Ghostâ€™s Name displayed prominently near the image.
o	Ghostâ€™s Level (e.g., â€œLevel 3â€) and maybe XP progress (like a small XP bar indicating progress to next level).
o	Hunger and Mood displayed with small bars or icons+percentage. These should update live. For visual appeal, use colored bars or emojis (ðŸ Full, ðŸ˜¢ if low mood, etc., perhaps tooltips on hover to explain).
o	If the ghost is at low stats, maybe the bars are red/empty; if full, green/full.
o	Possibly the ghostâ€™s last message or status: for example, a text like â€œGhost: Iâ€™m feeling happy!â€ derived from mood or last chat. (Not essential, but adds personality.)
â€¢	Action & Chat Panel: This area includes:
o	The Feed and Play buttons, likely as large buttons or icon-buttons. On web, they could be side by side at the top of this panel. E.g., a â€œFeed Ghostâ€ button (with icon) and â€œPlay with Ghostâ€ button.
o	When clicked, immediate feedback can be given: maybe temporarily disable the button or change its label to â€œFed!â€ then back, and update the stats on the ghost card (and ghost card could animate e.g., flash green on hunger bar increase).
o	Could also show a little ghost emoji reaction next to the avatar (like a heart emoji floating up to indicate happiness).
o	The Chat interface below the buttons: Very similar in function to the iOS chat:
o	A scrollable chat log showing past messages (maybe persist between sessions by loading recent messages from DB if stored, or just current session).
o	Each message labeled by who said it (maybe â€œMe:â€ vs the ghostâ€™s name or â€œGhost:â€), or use chat bubble style without labels (just alignment and color differences).
o	The ghostâ€™s messages might be styled in a playful font or color to differentiate (but ensure readability).
o	The input box at bottom (â€œType a messageâ€¦â€) and a send button. Possibly also an emoji picker or microphone icon if voice input was considered (probably not for hack due to complexity).
o	While waiting for a reply, show a â€œGhostagotchi is thinking...â€ or an animated typing indicator (like 3 dots).
o	The panel should gracefully handle long messages (wrap text) and allow scrolling. Also ensure on mobile view the virtual keyboard doesnâ€™t hide the input field (standard responsive design issue; Next.js with proper meta viewport should handle it, maybe need some JS to scroll chat up).
â€¢	Responsive behavior: On a narrow screen (mobile), the ghost card might stack above the chat panel. The feed/play buttons could perhaps be with the ghost card or above the chat input to save space. We have to design it so that on a phone browser, one can still chat easily (maybe the ghost image is small or hidden and focus is on chat interface).
â€¢	Real-time feedback: If the ghostâ€™s data changes from elsewhere, the ghost card updates. For example, if the user fed the ghost on their phone, and then quickly refreshes or checks the web, the hunger bar should already reflect full. With realtime subscription, if the web was open during feed from iOS, it would update immediately showing the new stat and possibly even appending a system message like â€œGhost was fed on another deviceâ€ (optional).
â€¢	Leaderboard Page: Accessible via nav (and not requiring login to view):
â€¢	Page header: â€œðŸ‘» Ghost Leaderboardâ€.
â€¢	A list (table or just cards) of top ghosts:
o	For each entry: Rank #, Ghost Name, Level, Owner Name/Handle (if we decide to show it), maybe one stat like â€œAgeâ€ (time since created) or mood for flavor.
o	We can style each entry as a row or a card with ghost emoji or mini-icon. Possibly highlight the first place (crown icon or special border).
o	If the user is logged in and their ghost isnâ€™t in top N, we might show â€œYour ghost: rank X (Level Y)â€ at bottom or top so they know where they stand (nice to have).
â€¢	This page should be attractive since itâ€™s public. Maybe include some ghost illustrations or a background. Ensure it fits the theme (dark, spooky but fun).
â€¢	If clicking on an entry is allowed, either nothing or it could pop up a small profile: showing that ghostâ€™s name, owner (maybe anonymous or a nickname), level, maybe a â€œSay hiâ€ button (which we wonâ€™t implement chat with others, out of scope).
â€¢	The data can be static at page load or refresh via a â€œRefreshâ€ button.
â€¢	Profile/Settings Page (Web): If the user clicks on their name or â€œProfileâ€:
â€¢	A simple form showing their email (read-only) and a field for â€œDisplay Nameâ€ if we support it (so they can appear on leaderboard or future social features with a nickname). They can update it and save (which calls an update to the profiles table).
â€¢	Possibly an option to change password (could link to Supabaseâ€™s magic link flow or not do it for hack).
â€¢	A logout button (redundant if nav already has).
â€¢	This page would be mostly functional, not heavily used once set, so can be plain form style.
â€¢	Notifications (Web): We likely wonâ€™t implement web push notifications due to complexity, but within the UI:
â€¢	If certain events happen (like ghost level up), we might show a toast message: â€œðŸŽ‰ Your ghost leveled up to 5!â€.
â€¢	Or after inactivity, show a reminder banner if the user returns: â€œYour ghost was very hungry! Good thing youâ€™re back.â€
â€¢	These are optional sugar.
â€¢	Error states & Loading (Web):
â€¢	On initial load of dashboard, have a loading spinner or skeleton UI while fetching ghost data.
â€¢	If fetching fails, show a clear message and a retry.
â€¢	For chat errors, show the ghostâ€™s reply as â€œ(The ghost is silent... maybe check your connection.)â€ or an error popup.
â€¢	For any protected page access without login, redirect to login with maybe a message â€œPlease login to continue.â€
â€¢	Theming and Aesthetics (Web):
â€¢	Continue the spooky-cute theme: likely a dark background (maybe an image of a haunted house silhouette or subtle pattern). Text in light colors. Accent colors could be purple or orange for buttons or highlights.
â€¢	Use ghost-related imagery: e.g., ghost icon for the app logo in nav, ghost emoji in texts.
â€¢	Choose a friendly font for headings (maybe a slightly whimsical font for ghost name or titles) but keep body text readable (sans-serif standard).
â€¢	Possibly include Halloween elements like stars, bats, or candy icons in minor UI decorations to boost visual appeal (especially if going for Costume Contest design points, though our focus is Frankenstein tech combo, a bit of costume flair wonâ€™t hurt).
â€¢	Mobile Web Behavior: Ensure that if a user uses the web on mobile (especially Android users who canâ€™t run the iOS app):
â€¢	They can still do everything: the chat input isnâ€™t hidden, buttons are tap-friendly (use adequate size).
â€¢	Possibly allow adding to home screen (PWA) if trivial to enable, but not necessary.
â€¢	The AR feature is not on web, but maybe we could consider a very lightweight AR substitute for web like an animated ghost on camera using WebAR library â€“ this is out-of-scope. Instead, we accept that the web doesnâ€™t have AR visuals.
User Flow on Web (Summary): User navigates to site â†’ Logs in â†’ Sees Dashboard with ghost info â†’ Performs actions (feed, chat, etc.) â†’ Maybe navigates to Leaderboard to compare â†’ Logs out when done. The web is designed for efficiency: quick access to info and actions, whereas the iOS app is designed for immersive interaction. Both share the same underlying metaphors (ghost with stats, chat with ghost) just presented differently.
In both platforms, the major UI components are the ghost display (AR or image), the status indicators, the action controls (feed/play), and the chat interface. These components map to core features, and consistency is maintained in terminology and feedback (feeding always triggers a happy reaction, etc.). By carefully designing these elements, we ensure that users have a delightful experience with minimal confusion, and the ghost pet concept is communicated clearly.
6. Backend Data Schema (Prisma + Supabase)
Ghostagotchiâ€™s backend uses a PostgreSQL database (via Supabase) to persist all data. We will design the schema using Prisma (an ORM) for type-safe database access and migrations. Below is the full data model with tables (Prisma models) and their fields, relationships, and relevant constraints:
â€¢	User / Profile: Supabase provides an auth.users table for authenticated users (with fields like id, email, etc.). Rather than duplicating those, weâ€™ll link to it. We create a Profile table for any additional user info.
â€¢	Profile (table profiles):
o	id (UUID, primary key) â€“ corresponds 1-to-1 with the userâ€™s auth ID (we will set id = auth.users.id).
o	username (Text, unique, nullable) â€“ a display name or nickname chosen by user for the leaderboard. (We may allow null and then use part of their email or â€œAnonymousâ€ on leaderboard if not set.)
o	created_at (Timestamp) â€“ when profile created (default now()).
o	updated_at (Timestamp) â€“ auto-updated on changes.
o	Relations: id foreign key references auth.users.id. We enforce ON DELETE CASCADE so if a user is deleted from auth (unlikely), profile goes too. One-to-one relation with Pet (profile has one pet).
o	Note: In Prisma, weâ€™ll represent this and possibly map it to the auth schema. Alternatively, we might skip a separate profile and store display name in Pet or use Supabaseâ€™s user user_metadata for a nickname to reduce complexity. However, a profile table is more structured.
â€¢	Pet: The core table representing the ghost pet.
â€¢	Pet (table pets):
o	id (UUID, primary key) â€“ unique ID for the pet (we can use Supabaseâ€™s uuid_generate_v4() default for this).
o	user_id (UUID, unique) â€“ references the ownerâ€™s auth.users.id (or we could reference profiles.id since theyâ€™re same). This has a unique constraint because each user can only have one pet. This is effectively a one-to-one relationship between user and pet.
o	name (Text) â€“ the name of the ghost (given by the user at creation).
o	level (Integer) â€“ ghostâ€™s current level (starting at 1).
o	experience (Integer) â€“ cumulative experience points. We might use this to calculate level (e.g., every 100 XP = +1 level, etc.). We can increment this on interactions.
o	hunger (Integer) â€“ current hunger meter (0-100). 100 means full/satisfied, 0 means starving. Defaults to 100 when created (full stomach). Decreases over time or by some schedule.
o	mood (Integer) â€“ current happiness/mood (0-100). 100 = very happy, 0 = very sad. Defaults to e.g. 50 or 100 on creation (assuming a new ghost is happy or neutral).
o	last_fed_at (Timestamp, nullable) â€“ last time the ghost was fed. Used to calculate hunger decay.
o	last_played_at (Timestamp, nullable) â€“ last time user played with it (or interacted to raise mood).
o	created_at (Timestamp) â€“ when pet was created/adopted.
o	updated_at (Timestamp) â€“ auto-update when any field changes (Supabase can handle with trigger, or we manage via application).
o	ghost_persona (Text, optional) â€“ a stored description of the ghostâ€™s personality or any custom prompt for the AI. For example, we might allow the user to set a short bio like â€œA mischievous but kind ghost from an old library.â€ This could be appended to the AI prompt for customization. If not set, we use a default persona. (This field can be null or default generic persona).
o	Relations: user_id foreign key references auth.users.id (or profiles). We will ensure this is unique (one pet per user). We might mark user_id also as the owner in Prisma relation to User (even if User is not a Prisma model, we can still refer to the foreign key).
o	Index/Constraints: Unique index on user_id. Perhaps an index on level for leaderboard queries (or we can just ORDER BY, index not strictly needed if dataset small, but in future for many entries, indexing level or a composite of level+xp might help leaderboard queries).
o	RLS Policies: We will enable RLS on this table: a policy that allows a user to SELECT and UPDATE their own pet where user_id = auth.uid(). (Also allow insert when auth.uid() = new.user_id so they can create their pet row once.)
o	Sample data example: { id: 123e4567-e89b..., user_id: abc-uid, name: "Casper", level: 2, experience: 250, hunger: 80, mood: 90, last_fed_at: 2025-11-05 10:00, created_at: 2025-11-01 ... }
â€¢	Chat Messages (Optional): To support persistent chat history and possibly context for AI, a table for messages:
â€¢	Message (table messages):
o	id (Serial or bigserial, primary key) â€“ unique message ID (or use UUID as well, but order matters more than global uniqueness, so serial is fine).
o	pet_id (UUID) â€“ references the ghost (pets.id) this message is associated with.
o	sender (Text or enum) â€“ who sent it: possible values: 'user' or 'ghost' (or we could store user_id or ghost as separate but since ghost is just an AI, marking 'ghost' is fine). If needed, we might store the actual user_id for user messages for clarity, but since one user per pet, it might be redundant to store user_id on each message.
o	message (Text) â€“ the content of the chat message.
o	created_at (Timestamp) â€“ time sent.
o	Possibly tokens_used (Integer) â€“ to track API usage per message (if we decide to log how many tokens the AI response was, not crucial for functionality).
o	Relations: pet_id foreign key -> pets.id. We might cascade delete if pet is deleted (which itself cascades if user deleted).
o	Usage: This table can store conversation logs. We might only keep recent messages (e.g., last 20) if worried about growth, but given low usage itâ€™s fine to accumulate some for the hack. It allows the web and iOS to show consistent conversation transcripts.
o	RLS policy: user can select their petâ€™s messages (join with pets to ensure same owner) and insert new messages for their pet. This is doable with a policy using auth.uid() match via pet relation.
o	This is optional; the app can function without storing messages (just live in memory per session). But storing improves cross-device continuity of chat.
o	If implemented, the Next.js chat API would insert user message to DB, call AI, insert ghost reply to DB, then return the reply. Clients then update via realtime or immediate response. Alternatively, we skip storing user message in DB and only store ghost replies, but then we lose some context. Itâ€™s likely easier not to store every single user prompt due to time, but SRS including it shows completeness.
â€¢	Leaderboard View: We might not need a separate table, as leaderboard is derived from Pet data (order by level/XP).
â€¢	If we wanted to persist historical rankings or such, a separate table could track â€œscoresâ€, but here the Petâ€™s level is the score.
â€¢	We may create an SQL view or simply query pets sorted by level desc, experience desc, created_at asc (in case of ties give edge to older or earlier one).
â€¢	If a view is created (like top_pets), it might join with profile to get username if needed.
â€¢	Not necessarily represented in Prisma as a model (Prisma could query raw SQL or we can just use ORM sorting).
â€¢	Other Tables (considerations):
â€¢	If we had more time/features: Achievements, Notifications, etc., but not required now.
â€¢	Supabaseâ€™s auth.users will store email, hashed password, and optionally last login etc. We donâ€™t duplicate those. We might use triggers: e.g., Supabase allows a trigger after new user signup to insert a profile row. We could set that up: on insert to auth.users, create a profiles row with same id. For hack, we can also just create profile in our app logic after sign-up.
â€¢	If using Supabase storage for images (like ghost avatar pictures), weâ€™d have a bucket for images and store URLs in the DB. Currently, ghost images are static in-app, so no need.
Below is a simplified Prisma schema snippet reflecting the above structure (for illustrative purposes):
model Profile {
  id        String   @id @default(dbgenerated()) @map("id") // will map to auth.users UUID
  username  String?  @unique
  createdAt DateTime @default(now()) @map("created_at")
  updatedAt DateTime @updatedAt @map("updated_at")
  pet       Pet?
  // relation: one profile can have one pet
}

model Pet {
  id           String   @id @default(uuid()) 
  userId       String   @unique @map("user_id")
  name         String
  level        Int      @default(1)
  experience   Int      @default(0)
  hunger       Int      @default(100)
  mood         Int      @default(100)
  lastFedAt    DateTime?@map("last_fed_at")
  lastPlayedAt DateTime?@map("last_played_at")
  ghostPersona String?  @map("ghost_persona")
  createdAt    DateTime @default(now()) @map("created_at")
  updatedAt    DateTime @updatedAt @map("updated_at")

  // Relations
  profile      Profile? @relation(fields: [userId], references: [id]) // if linking to Profile.id (which is user id)
  // Alternatively reference auth.users via @@map on schema, but Prisma doesn't support direct foreign to external schema easily.

  messages     Message[]
}

model Message {
  id        Int      @id @default(autoincrement())
  petId     String   @map("pet_id")
  sender    String   // 'user' or 'ghost' - could use enum but simple string for now
  message   String
  createdAt DateTime @default(now()) @map("created_at")

  // Relations
  pet       Pet      @relation(fields: [petId], references: [id])
}
(Note: The actual Prisma schema might need a custom setup to reference Supabase auth schema. Alternatively, we might treat the Profile model as representing the auth user as well with same ID.)
Database Relationships: The main relationship is one-to-one between User and Pet. Each Pet belongs to one User, and each User has at most one Pet. We enforce this with a unique constraint on pets.user_id. The Profile (User) to Pet is one-to-one. The Pet to Message relationship is one-to-many (a pet can have many messages; each message links to one pet).
Schema Constraints & Business Rules: - A user cannot create more than one pet (the app should check and the DB will reject a second pet insertion due to unique constraint). - If a user is deleted (which is rare, but if removing an account), cascade delete their profile and pet and messages to clean up. - The stats (hunger, mood, etc.) should ideally be constrained between 0 and 100. We could enforce that via application logic or a CHECK constraint in SQL (e.g., CHECK (hunger BETWEEN 0 AND 100)). We might add such constraints for data integrity. Similarly for mood. - We might add a trigger or computed column for level if we wanted level to be auto-derived from experience. But currently, we will manage level in app logic (increase level when XP crosses a threshold). - The updated_at is auto-managed by either Prisma or DB triggers to track last modification (useful for syncing or knowing last time ghost state changed).
Using Prisma with Supabase: We will create the schema in the Prisma data model and run prisma migrate which will generate SQL to create these tables in the Supabase database (public schema). We have to ensure the Supabase uuid-ossp extension is enabled for UUID generation (Supabase by default enables it, so uuid() should work). Also, weâ€™ll likely create the RLS policies via SQL (Prisma migrate can run raw SQL migrations to set those up).
Initial Data: On project start, no pets exist. Profiles will be created upon user signup. Optionally, for development we might seed a couple of ghosts for testing the leaderboard.
The above schema provides a solid foundation for the applicationâ€™s data. It cleanly separates concerns (User vs Pet vs Messages) and will support the required queries: - Get a userâ€™s pet: query pets by user_id. - Update pet stats: update pets set hunger=.., etc. - Leaderboard: query pets ordering by level/experience, join profile for username if needed. - Chat history: query messages by pet_id ordering by created_at.
The data model is relatively small and simple, which is advantageous for a hackathon project (quick to migrate and manage). The use of Prisma ORM means weâ€™ll have generated TypeScript/JavaScript client code to easily query and update these records from the Next.js backend, and likewise we can use Supabaseâ€™s client directly for straightforward operations (especially for real-time listening on pets and selecting data on the client).
To summarize, the Prisma + Supabase schema ensures persistence of all crucial information: user identities, ghost pet states, and interactions. It is designed to enforce the game rules (one pet per user, stat ranges) and to facilitate the features like the leaderboard and chat. The structure is also future-proof enough to allow adding more attributes or related features (for instance, more pet attributes or linking pets together for multi-ghost interactions, etc.).
7. API Routes and Endpoints
Ghostagotchi will utilize a combination of RESTful API endpoints and Supabaseâ€™s built-in database API. We describe here the key endpoints (mostly implemented as Next.js API routes) that the clients will use. These endpoints either perform operations (like feeding the ghost, or processing chat with AI) or serve data (like the leaderboard). In addition, we mention how Supabaseâ€™s auto-generated REST endpoints or RPCs might be used as alternatives.
Authentication Endpoints: (Provided by Supabase) - We rely on Supabaseâ€™s auth API for login/signup: - POST https://<supabase_project>.supabase.co/auth/v1/signup â€“ used internally by the Supabase client when a user signs up (with email, password). - POST .../auth/v1/token?grant_type=password â€“ for login (again handled by Supabase JS or iOS SDK). - Social OAuth endpoints are handled via Supabase, which after success redirect back to our app with a token. - We do not have to create custom auth endpoints in Next.js because Supabase handles these via SDK. The clients will use the SDK functions like supabase.auth.signInWithPassword({ email, password }). - After login, the clients get a JWT which is used in subsequent requests.
Protected API with JWT: For our Next.js API routes, we will use the Supabase JWT (passed in Authorization header or cookie) to verify the user. Next can utilize supabase-auth-helpers or we manually decode token to get user.id.
Now the custom endpoints:
â€¢	GET /api/pet â€“ Get current userâ€™s pet data.
â€¢	Description: Returns the pet object for the authenticated user. This is useful for initial loading of the dashboard or app.
â€¢	Auth: Requires authentication (we will check the userâ€™s token).
â€¢	Operation: The server finds the pet where user_id = auth.uid in the database (likely using Prisma or Supabase client). It then returns JSON like:
    { "id": "...", "name": "Ghosty", "level": 2, "experience": 150, 
  "hunger": 80, "mood": 90, "last_fed_at": "...", "last_played_at": "...", 
  "created_at": "...", "updated_at": "..." }
    Possibly including related info like username if needed.
â€¢	Error cases: If no pet exists for user, return 404 or an empty result (the client would then know to prompt creation). If unauthorized, return 401.
â€¢	Note: We might not need this if clients fetch pet via Supabase direct query using their client key. On web, we could SSR this data as well. But having an API route makes it easy to ensure secure retrieval in one call.
â€¢	POST /api/pet â€“ Create a new pet (adopt ghost).
â€¢	Description: Creates a pet for the authenticated user. Only used when a new user completes the ghost naming step.
â€¢	Request body: JSON with initial parameters (e.g., { "name": "Specter" } â€“ the chosen ghost name). We can ignore stats because defaults will be applied.
â€¢	Operation: Server will insert a new pet row with the given name and default stats (level 1, exp 0, hunger 100, mood 100, etc.) and user_id = current user. We must ensure the user has no existing pet (to enforce one pet). If they do, respond with an error.
â€¢	Response: The created pet object (or at least the new ID and any fields).
â€¢	Errors: 400 if name missing, 409 if user already has a pet, 401 if not auth.
â€¢	This could also be done client-side by calling Supabase REST, but doing it in our API allows the unique-check logic and default handling in one place.
â€¢	PUT /api/pet â€“ Update pet attributes.
â€¢	Description: Allows updating certain fields of the pet, like renaming the ghost.
â€¢	Request body: JSON with fields to update, e.g. { "name": "NewName" } or { "hunger": 100, "mood": 100 }.
â€¢	Operation: Check auth, then update allowed fields on the userâ€™s pet. This might not be used for feeding (we have a separate feed route), but for something like renaming the ghost or other bulk updates.
â€¢	Response: Possibly the updated pet data.
â€¢	We might not need a general update route if we have specific ones for actions.
â€¢	POST /api/pet/feed â€“ Feed the ghost action.
â€¢	Description: Performs the feeding action: updates the ghostâ€™s hunger to full (100) and possibly increases experience points.
â€¢	Operation:
o	Check auth, retrieve the userâ€™s pet.
o	Compute new values: hunger = 100 (or hunger + some increment capping at 100), last_fed_at = now(). Also decide XP gain, e.g., +10 XP. If XP crosses threshold for next level, increment level and possibly carry over extra XP.
o	Update the pet row in one atomic operation (so level, xp, hunger, last_fed_at fields).
o	Respond with the updated stats or a success message.
â€¢	Response example: { "hunger": 100, "level": 2, "experience": 160, "mood": 95 } (if mood might also increase slightly due to feeding).
â€¢	This could be implemented as a Postgres function (RPC) instead for atomicity. For example, a SQL function feed_pet(userid UUID) that does the update and returns the updated row. We might consider that: then the client could call it via Supabase RPC. But given we have Next.js, implementing it in Node (with transaction) is fine.
â€¢	Using the Next approach, we ensure the logic is in one place and can also broadcast a custom event if needed (though Supabase realtime will handle broadcasting the DB changes).
â€¢	Errors: 403 if user tries to feed a pet that isnâ€™t theirs (shouldnâ€™t happen if auth and RLS work). Maybe 429 or 400 if feeding too soon (we could enforce a cooldown by checking last_fed_at â€“ e.g., if last_fed_at less than 1 minute ago, we could reject to prevent spamming).
â€¢	After this endpoint completes, the changes in DB trigger realtime updates to clients.
â€¢	POST /api/pet/play â€“ Similar to feed, but for the play action affecting mood.
â€¢	If we implement a distinct play action: it would set mood = 100 or +X, update last_played_at, add XP, etc.
â€¢	Could also be merged with feed route by having an action type parameter, but clarity is nicer with separate endpoints.
â€¢	POST /api/chat â€“ Handle AI chat message.
â€¢	Description: Processes a userâ€™s chat message by querying the OpenAI API and returning the ghostâ€™s response.
â€¢	Request: JSON with at least message: "user's message text". Could also include conversation context or message history if we want the server to manage that (or we retrieve recent messages from DB).
â€¢	Operation:
o	Check auth, determine the userâ€™s ghost (for context like name or persona).
o	Construct the prompt for OpenAI:
o	System prompt: something like â€œYou are Ghostagotchi, a friendly ghost pet. You speak in a fun, spooky way. You know your name is X and you love your owner. Keep responses concise.â€ (We can include ghostâ€™s name and maybe some stats-based mood, e.g., if mood is low, perhaps the ghost acts a bit sad in tone).
o	User prompt: the message from the request.
o	(Optionally include a brief summary of the last few messages if we have them stored, to maintain context â€“ e.g., last user and ghost messages).
o	Call OpenAIâ€™s Chat Completion API (with model GPT-4 or GPT-3.5) using the above prompt. Temperature maybe around 0.7 to keep it creative but not too random.
o	Await the response. Parse out the assistantâ€™s reply text.
o	Optionally, store this interaction: e.g., write the user message and the ghost reply into the messages table for history.
o	If performance is a concern, we might not want to wait on two DB writes (but theyâ€™re quick). We could do them after sending response (but then user might not see if fail). Simpler: do it sequentially - insert user message, insert ghost message.
o	Return a JSON response: { "reply": "<ghost reply text>" }. Possibly also include any additional metadata (like maybe updated mood if we decide the ghostâ€™s mood improves because the user chatted with it).
â€¢	Response: The ghostâ€™s reply string. The client will display it.
â€¢	Errors: If the OpenAI API errors (e.g., 500 or timeout), respond with an error code (500) and maybe a friendly message. If the userâ€™s message was empty or too long, respond 400. If unauthorized, 401.
â€¢	Security: We must ensure only the authenticated user can invoke chat for their ghost. Thatâ€™s naturally ensured if we tie the ghost persona to userâ€™s pet and not allow a user_id parameter to be injected (we derive it from the token). So one user canâ€™t chat as another userâ€™s ghost via this endpoint.
â€¢	Note: We should also consider the cost â€“ this endpoint should possibly restrict extremely long messages to not blow token usage. We can enforce a max length on input (like 200 characters).
â€¢	This is a crucial endpoint as it ties together our app with OpenAI.
â€¢	GET /api/leaderboard â€“ Retrieve leaderboard data.
â€¢	Description: Returns the list of top ghosts for the public leaderboard.
â€¢	Auth: Could be not required (since itâ€™s public). If no auth, we only return public info. If user is logged in, we might highlight their ghost in response as well.
â€¢	Operation: Query the pets table for top N (say 10) ordered by level (desc) then experience (desc) then created_at (asc). Join with profile or auth.users to get an owner name if we want to include it. However, to keep it simple and privacy-preserving, we might not include userâ€™s actual name or email. Instead:
o	Either include username from Profile if set, else something like an anonymized ID (e.g., first 5 chars of user ID or email prefix).
o	Or do not include owner info at all, just ghost names and levels.
â€¢	Response: JSON array of entries, e.g.:
    [
  { "rank": 1, "ghostName": "Casper", "level": 5, "owner": "Alice" },
  { "rank": 2, "ghostName": "Spooky", "level": 4, "owner": "Bob" },
  ...
]
    The rank can be computed in the query or just derive from array index + 1.
â€¢	Implementation: This could be done directly with Prisma query: findMany pets, orderBy, limit. Or using a raw SQL if needed. If RLS is enabled (which would normally block reading others' pets), we will either disable RLS for this select via a service role, or use a Postgres function with SECURITY DEFINER to bypass RLS. Another approach: maintain a separate table or view that is publicly readable with the necessary fields (perhaps easier: create a view public_leaderboard that selects ghost name, level, profile.username from each pet, and set RLS to allow all select on that view).
â€¢	For hack simplicity, we might temporarily allow read access to pets for this route by using the service role key on the server side. (This is acceptable because the server is trusted; weâ€™re not exposing the key to client.)
â€¢	No special errors unless something goes wrong. If no pets, returns empty list.
â€¢	Other Endpoints:
â€¢	POST /api/profile â€“ Update profile (like username). (If we let user set display name).
o	This would just update the profiles.username for the user. Request body might be { "username": "GhostMaster" }.
o	Weâ€™d ensure no duplicate username exists (since we set unique). If taken, respond 409 conflict.
â€¢	GET /api/profile â€“ Possibly to get the logged-in user profile (though not really needed as we can embed profile data in pet or use supabase auth directly).
â€¢	These are minor and not critical if profile is a small feature.
Supabase Auto-Generated Endpoints: Supabase provides a RESTful interface at https://<project>.supabase.co/rest/v1/<table> for each table, with queries controlled by URL params and headers for auth. We could utilize those instead of building custom endpoints for simple CRUD: - For example, the mobile app could do POST /rest/v1/rpc/feed_pet if we created that RPC in the DB, passing needed parameters, and Supabase would execute it (with RLS applied appropriately). - Or the web could do a GET on /rest/v1/pets?select=...&order=level.desc&limit=10 with an admin api key to get leaderboard. - However, since we have a Next.js server, we can funnel most interactions through it for more control and to integrate with OpenAI. We will use Supabaseâ€™s SDK primarily for realtime and perhaps for the initial fetch of data on clients.
Webhooks / Real-time Endpoint: Not exactly an API endpoint, but we mention: - Supabase realtime works via websockets subscribed on tables. We donâ€™t need to create an endpoint for it; the clients directly use the library to listen. - If we wanted server to push some custom events, we could use Supabaseâ€™s Broadcast feature to send events to channels (for instance, if we had a global event or chat). But our use-case doesnâ€™t require custom server-sent events beyond DB changes.
System Architecture Integration: - The Next.js API routes (above) run on the server side. On Vercel or similar, each route is a serverless function handling requests. - The iOS app will call, for instance, the /api/chat endpoint on our Next.js server (with the userâ€™s JWT). The web app will do the same via fetch or using our own client code (like a function that calls internally). - We must ensure the Supabase JWT is accepted by Next: we might use supabase-auth-helperâ€™s middleware to automatically validate and get the user. Or decode the JWT with the Supabase public key. Simpler: we may use the fact that the supabase client on web can be configured to send a cookie (with the token) to our domain if same-site, etc. Given time, might do manual: - For the hack, itâ€™s fine to require the web client to call supabase.auth.getSession() then attach the token to our fetch requests. - The iOS app can do similarly by including the token in Authorization header of requests.
Summary of Key Endpoints: 1. POST /api/pet â€“ create ghost (called once per user typically). 2. GET /api/pet â€“ fetch ghost data (could also rely on supabase direct, optional). 3. PUT /api/pet â€“ update ghost (rename, generic updates). 4. POST /api/pet/feed â€“ feed action (update hunger, XP). 5. POST /api/pet/play â€“ play action (update mood, XP). 6. POST /api/chat â€“ chat with ghost (OpenAI integration). 7. GET /api/leaderboard â€“ get top ghosts list. 8. POST /api/profile â€“ set profile data like username (optional). 9. (Supabase Auth endpoints implicitly used for login flows.)
Each of these endpoints will be documented for the hackathon submission (so judges know how we utilized backend logic). The design ensures that game logic (feeding, leveling, chat) is primarily handled on the server side, which centralizes control and security. In some cases, we might decide to move certain logic to database functions (for a more backend-leaning approach using Supabase RPC), but given the Next.js component, our approach is to implement them in Node using Prisma for DB and axios/OpenAI SDK for AI.
By providing these clear endpoints, the appâ€™s frontends (iOS and Web) have a straightforward interface to interact with the backend, beyond what Supabaseâ€™s generic APIs offer. This separation also makes it easier to maintain and test the core functionalities (we can unit test the feed or chat handlers in isolation).
8. System Architecture Diagram and Flow
Ghostagotchi system architecture, illustrating the client apps, backend services, and their interactions. The architecture consists of two client applications (iOS app and Next.js web app) that communicate with a shared backend. Both clients rely on Supabase (Postgres) for data storage, authentication, and realtime sync. The Next.js server (part of the web app) functions as a middle-tier: it uses Prisma ORM to read/write the database and handles AI requests by calling the OpenAI API. Supabaseâ€™s real-time engine (via websockets) pushes updates from the database to clients, ensuring live synchronization.
Key Components and their Roles:
â€¢	iOS Mobile App: A native app written in Swift/SwiftUI. It contains the AR Ghost UI and communicates with Supabase directly for authentication and database operations. It uses the Supabase Swift SDK to, for example, subscribe to real-time updates on the petâ€™s record and to call Supabaseâ€™s REST endpoints if needed. For AI chat, the iOS app sends user messages to the Next.js backend (HTTP call to the /api/chat endpoint) since the OpenAI API key is not stored on-device. The iOS app receives ghost responses from that endpoint to display to the user. It also uses supabase real-time to get immediate updates (like hunger changes) when the web or backend triggers them.
â€¢	Web Dashboard (Next.js): This has two parts:
â€¢	The Next.js Client (browser) â€“ a React application served to users. It uses the Supabase JS SDK for authentication (managing the user session) and for real-time subscriptions to the database. For example, after loading, it might call supabase.from('pets').select(...) to get the ghost state or supabase.channel('schema:public:pets').on('postgres_changes', ...) to listen for updates. The web client also communicates with the Next.js server via API calls. When a user on web clicks â€œFeedâ€ or sends a chat message, the React app will make a fetch request to the appropriate API route (e.g., POST /api/feed or POST /api/chat). The web client then updates the UI optimistically or waits for the response.
â€¢	The Next.js Server (Node.js) â€“ this runs server-side logic (API routes and SSR). It is connected to the Supabase Postgres through Prisma. The serverâ€™s responsibilities include: handling secure operations (like the OpenAI integration), performing complex DB updates (like feed/play logic, which it can do through Prisma transactions), and assembling data for pages (for SSR, e.g., it can fetch leaderboard data on the server before sending the page). The Next.js server has access to a Supabase service role or DB credentials (stored securely) to perform operations beyond what the client can (such as reading all pets for the leaderboard bypassing RLS, if needed).
â€¢	The Next.js server also uses Supabase Auth helpers to verify incoming requestsâ€™ JWTs â€“ ensuring the user calling an API route is authenticated.
â€¢	Supabase Backend: This encompasses several subcomponents:
â€¢	Supabase Auth: Manages user accounts (email/password, OAuth). Both iOS and web apps use it for login. After login, they receive a token (JWT) which is used for subsequent calls. The Auth system is integrated with the database (the auth.users table and Row-Level Security policies use auth.uid()).
â€¢	Postgres Database: Hosts the data tables (profiles, pets, messages, etc.). All persistent state lives here. For instance, when the user feeds the ghost, the hunger value in the pets table is updated in this database. The DB also contains any stored procedures we might add (like feed_pet()), and enforces constraints and RLS policies.
â€¢	Supabase Realtime: A real-time listening service that watches Postgres changes and pushes them to subscribed clients. As depicted, whenever the pets table is updated (say the hunger field changes), Supabase Realtime will send a WebSocket message to both the iOS app and the web client (if they are subscribed to that event). This is how the iOS app knows that the ghost was fed from the web, and vice versa. Supabase can filter events by user or other criteria, but likely each client subscribes specifically to their ghostâ€™s record or to changes on the pets table with a filter.
â€¢	Supabase Storage (optional): Not heavily used in this project except possibly for storing an avatar image if needed. The architecture can accommodate it (for example, if we had ghost images uploaded by users, the clients would retrieve them from here).
â€¢	OpenAI API: An external service (OpenAIâ€™s servers) offering AI model access (ChatGPT/GPT-4). The Next.js server communicates with OpenAI over HTTPS. The sequence is: client sends message to Next.js â†’ Next.js calls OpenAI API with appropriate prompts â†’ receives response â†’ Next.js returns it to client. The OpenAI API in the diagram is separate from our cloud infrastructure but is a crucial part of the ghostâ€™s â€œbrain.â€ We will secure the API key on the server. Both the iOS and web funnel AI requests through this server component.
Data Flow and Sequence Example:
1. User Authentication: The user logs in on either iOS or Web. The app uses Supabase Auth (direct SDK calls) â€“ if successful, Supabase returns a JWT and possibly refresh token to the client. The client now includes this token in future requests (implicitly via Supabase client or manually in our fetches). The userâ€™s presence might be tracked via Supabase (if using presence feature to mark them online, but thatâ€™s optional). 2. Fetch & Subscribe: The client (iOS or web) on startup fetches the ghostâ€™s current data from Supabase (either via our API or direct query) and then opens a real-time subscription to pets (filter by their petâ€™s ID). It also might subscribe to messages if we want live chat updates. 3. Feeding the Ghost (Write Path): Suppose the user on the web dashboard clicks â€œFeed.â€ The web client sends a POST /api/pet/feed request to the Next.js server, including the userâ€™s auth token. The Next.js API handler verifies the token (decodes it to get user ID), uses Prisma to find that userâ€™s pet row, updates the hunger (and other stats) in the Postgres database. Once the DB write is successful, it responds to the web client with the updated values. Simultaneously, that DB update triggers Supabase Realtime: it detects an update in pets table. The Supabase Realtime service then broadcasts a message over websockets to any subscribers of that event. The iOS app, which is subscribed to its pet data, receives the event (with the new hunger value, etc.). The iOS app then updates its UI (e.g., fills the hunger bar). The web client that initiated the feed might also get the event (if itâ€™s subscribed too), or it can simply update its state from the response it got. In either case, both clients are now in sync. This whole feed action happens in a fraction of a second: Next.js request maybe ~100ms, realtime push maybe ~100-200ms more to reach the other device. 4. Chat with Ghost (Read/Write with external API): The user on iOS enters a chat message. The iOS app sends an HTTPS request to the Next.js serverâ€™s /api/chat route (with the JWT for auth and the message text). The server receives it, verifies user, and then forms a call to OpenAI. The request goes out to OpenAIâ€™s cloud (this might take e.g. 1-2 seconds for GPT-4). When OpenAI responds with the ghostâ€™s reply, the Next.js server can optionally save the conversation to the DB (in messages table) and then returns the reply to the iOS app. The iOS app displays it. If we saved it to DB and the web is subscribed to messages, the web would get a realtime event for a new message and could display it as well. If we didnâ€™t store messages, the web wouldnâ€™t know unless it was actively engaged in the same conversation (so for cross-device simultaneous chat, storing messages is beneficial). The key is that the OpenAI integration is encapsulated on the server â€“ the clients never talk to OpenAI directly. 5. Leaderboard Display: When a user (or even a public visitor) opens the leaderboard page (Next.js web), the Next.js server queries the database (via Prisma or Supabase) for top pets. This query uses an admin context (since itâ€™s the server) to bypass RLS and gather all usersâ€™ pet info needed. It then renders the page (SSR) or returns JSON for the client. The leaderboard page can also use realtime subscription if we want it live; e.g., subscribe to changes on pets table where level or exp changes, and update the list dynamically. This could be a bit complex to manage ordering, but possible for a small number of top entries. Alternatively, we periodically refresh the data client-side. The architecture supports either approach â€“ all reading still comes from the central Postgres. 6. Kiro Development Integration: (This is more about how we built the system, not runtime flow, but worth noting in architecture): Kiro itself runs as an IDE environment on the developerâ€™s machine. Itâ€™s not shown as a runtime component in the diagram, but conceptually, Kiro sits â€œoutsideâ€ the system and interfaces with our code repository and possibly with external docs (via MCP). For example, while coding, Kiroâ€™s agent might use the steering files to understand our project structure and generate code accordingly, and use specs to ensure it meets requirements. When we commit code or perform tasks, agent hooks might trigger, etc. In the architecture, Kiro helped shape the code of each component but does not appear in the deployed product environment.
Infrastructure and Deployment: - The Supabase instance (which includes the Postgres DB and realtime server) is cloud-hosted (likely in a specified region, say US or EU). - The Next.js app will be deployed on a platform like Vercel (which is well-suited for Next). Vercel will host the static front-end pages and serverless functions for the API routes. Weâ€™ll configure environment variables on Vercel (Supabase connection string, API keys). - The iOS app will be compiled and possibly distributed via TestFlight for testing. It needs the Supabase project URL and public anon key (for using the APIs) embedded in it, as well as the base URL for the Next.js API (which could be the same domain if configured, or separate). - The OpenAI API is external SaaS. The Next.js server will have the OpenAI secret key as an env var. All calls to OpenAI go over internet from our serverâ€™s location to OpenAIâ€™s endpoints.
Scalability & Communication: - The diagram shows multiple clients can connect (indeed, multiple users each with their own ghost). Each has their own data. The Supabase realtime and database handle concurrent usage by different users by channel separation and RLS enforcement. - Within a single userâ€™s context, having two clients (web and iOS) is like a multi-client sync scenario â€“ which our design explicitly supports. - The architecture is essentially a client-server model augmented with a pub-sub (realtime) system: - Clients act on data and send requests to server/DB. - The server/DB updates state and then notifies all clients. - This ensures eventual consistency across devices with minimal delays.
Error Handling Flow: If any component fails: - E.g., if OpenAI is unreachable, the Next.js server returns an error for the chat request; the client can handle it (show message). - If Supabase goes down temporarily, both iOS and web will lose realtime connection (they might get disconnected events), and API calls to Supabase will fail. The app should alert the user or retry later. - If Next.js server goes down (maybe Vercel outage), web UI might still load (if cached) but chat/feed actions wonâ€™t work (since those routes wonâ€™t respond). The iOS appâ€™s chat feature would also not work. However, feeding could still be done via direct DB call as a backup if we coded it (e.g., using Supabase REST from iOS as a fallback). But ideally, we keep the Next backend up or have minimal logic that depends on it exclusively.
This architecture is fairly robust and modern: it leverages BaaS (Backend-as-a-Service) for core features and supplements it with a custom Node.js server for the AI part and any advanced logic. The diagram underscores that all stateful data lives in one place (the Postgres DB) and all interactions funnel through it either directly (with supabase clients) or indirectly (via our server). This central source of truth model greatly simplifies synchronization.
It also showcases how multiple technologies are integrated: - Native mobile + Web (different client frameworks) - Cloud database and realtime (Supabase) - ORMs and serverless functions (Prisma, Next.js API) - External AI service (OpenAI) - And of course, development-time AI assistance (Kiro, though not in runtime architecture, but conceptually part of the overall system creation).
In conclusion, the architecture achieves the goal of a â€œFrankensteinâ€ assembly of components[1] â€“ by making them work together seamlessly. The real-time update flow in particular is a highlight, as it demonstrates cross-platform state coherence which is a key aspect of Ghostagotchiâ€™s user experience.
9. Technical Stack
Ghostagotchi is built with a diverse set of technologies, each chosen for a specific strength and their ability to work in harmony. Below is the technical stack breakdown for each part of the project:
â€¢	iOS Mobile App:
â€¢	Language & Frameworks: Swift and SwiftUI are used to develop the iOS app, providing a modern, declarative UI toolkit. SwiftUI handles the interface (views, layouts, etc.), while UIKit might be used for any components or lower-level control that SwiftUI doesnâ€™t easily provide (for example, integrating ARKitâ€™s UIViewRepresentable or handling camera permissions).
â€¢	Augmented Reality: ARKit (Appleâ€™s Augmented Reality framework) is utilized to place and render the ghost in the real world through the deviceâ€™s camera. In conjunction, RealityKit or SceneKit will be used for the 3D rendering of the ghost model. RealityKit offers high-level AR rendering and might be preferred for simplicity (with SwiftUIâ€™s ARView). If needed, SceneKit can load a 3D model (like a .usdz file of a ghost) and manage animations.
â€¢	Networking & Auth: The app uses Supabase Swift SDK for interacting with the Supabase backend. This provides easy methods for user authentication (email/password login, etc.), database CRUD operations, and subscribing to realtime channels. If the official SDK is limited, we could use standard URLSession HTTP calls for our custom API routes (for example, sending the chat request to the Next.js endpoint).
â€¢	State Management: SwiftUIâ€™s state management (State, ObservableObject) will manage the ghostâ€™s data. For instance, a PetViewModel might subscribe to supabase realtime updates and update @Published properties for hunger, mood, etc., which the SwiftUI views bind to.
â€¢	AI Integration: No direct AI SDK on iOS; instead, calls go to the Next.js API. We might use URLSession or a library like Alamofire to call the /api/chat route.
â€¢	Third-party libraries: Possibly minimal. We may use Supabaseâ€™s Realtime library (if not part of main SDK) to handle sockets. If we need an image caching or a quick UI library, maybe not. For simplicity, stick to native frameworks and Supabase SDK.
â€¢	Development Tools: Xcode is used for development. We are also leveraging Kiro IDE as we code (more on that in section 10) â€“ Kiro assists in generating Swift code from specs and handling repetitive tasks.
â€¢	Web Dashboard (Frontend):
â€¢	Framework: Next.js (React) â€“ chosen because it supports both client-side interactivity and server-side rendering/APIs in one project. Next.js allows us to build a single web app that covers the UI and the backend for our needs.
â€¢	Language: TypeScript is used for type safety on the web code (both front and backend parts of Next.js).
â€¢	UI Library: React (JSX/TSX) with maybe a component library or styling framework:
o	We might use a CSS framework like Tailwind CSS for rapid styling (given the hackathon timeframe, Tailwindâ€™s utility classes can speed up making a decent-looking UI quickly). Alternatively, basic CSS Modules or styled-components in Next.js. If not Tailwind, possibly Chakra UI or Material-UI could be used for ready-made components, but Tailwind might align with fine-tuned spooky design easier.
o	For icons, maybe include something like Heroicons or FontAwesome for things like feed/play/chat icons.
â€¢	State Management: Reactâ€™s useState/useEffect plus perhaps Context or Redux for global state. But for simplicity, likely use Reactâ€™s context or just pass state down. Since Supabaseâ€™s real-time will directly update state via hooks, heavy state libraries might be unnecessary.
â€¢	Supabase Integration: Using @supabase/supabase-js library on the client to handle login and real-time subscriptions. Weâ€™ll initialize this with the project URL and anon public key.
â€¢	API Calls: For calling our own Next.js API routes, we use the browserâ€™s fetch or axios. We might create a small wrapper, for example:
o	fetch('/api/chat', { method: 'POST', headers: { Authorization:Bearer ${token}}, body: JSON.stringify({ message }) }).
o	Could also use Supabaseâ€™s PostgREST endpoints for certain things: e.g., to fetch pet data supabase.from('pets').select(...) but with RLS we have to ensure itâ€™s allowed. We likely rely on our token which Supabase client attaches behind scenes.
â€¢	Routing: Next.js pages for dashboard, leaderboard, etc. It can prerender leaderboard for SEO.
â€¢	Deployment: The Next.js app (frontend) will be deployed on Vercel (which is seamless for Next.js). Vercel will also host our API routes.
â€¢	Backend Services:
â€¢	Database: Supabase Postgres â€“ a managed PostgreSQL database with extensions. It stores our structured data. It provides Row Level Security which we configure for data protection. We use SQL (or Prisma migrations) to define tables. Also, Supabaseâ€™s PostgREST auto-exposes REST endpoints and realtime functionality which we use. The database is the backbone of cross-platform sync (via realtime) and persistent state.
â€¢	Prisma ORM: We use Prisma on the Next.js server to interface with the Postgres DB in a type-safe manner. Prisma will have our schema (as described in section 6) and we can use its client to run queries in our API routes:
o	e.g., const pet = await prisma.pet.update({...}) to feed the ghost.
o	Prisma also makes it easier to run complex queries or multi-step transactions in Node without writing raw SQL.
o	We will set up Prisma with a connection string to the Supabase DB (this string will be kept secret in environment variables).
o	As noted, Supabase is essentially Postgres â€“ fully compatible with Prisma[12]. Using Prisma doesnâ€™t conflict with Supabaseâ€™s other features; itâ€™s just a direct connection to the same DB that supabase clients use. We might turn off Supabaseâ€™s REST if we exclusively use Prisma to avoid conflicts (as their docs mention)[13], but in dev we can keep it on for quick debugging if needed.
â€¢	Next.js API (Node) & Middleware: This includes custom code for our endpoints like feed and chat. We might incorporate Supabase Auth Helpers for Next.js to simplify verifying JWT and getting user object in API routes. Alternatively, we decode JWT manually using the JWT secret from Supabase (provided in project settings).
o	The API routes might use libraries like node-fetch or Axios to call external APIs (OpenAI).
o	We will also include the OpenAI Node SDK (if available, e.g., openai npm package) for easier API calls. If not, we just do HTTP requests.
o	The Next.js environment will store secrets: the Supabase service role key (for privileged DB access if needed) and the OpenAI API key. These are not exposed to the client.
o	Potentially, use Rate Limiting libraries (like rate-limiter-flexible or simple in-memory counters) on the API routes to avoid misuse (e.g., limit chat calls per minute per IP/user).
â€¢	OpenAI API: Specifically, likely using OpenAIâ€™s Chat Completions endpoint with model â€œgpt-4â€ or â€œgpt-3.5-turboâ€. The technical detail: an HTTP POST to https://api.openai.com/v1/chat/completions with a JSON body containing our prompt and an authorization header with the API key. The response is JSON with the message. Weâ€™ll parse that in Node and return the content.
o	If using the official OpenAI library, it abstracts some of that. But we have to be mindful of timeouts; we might set a reasonable timeout (like 10s) for the request so the user isnâ€™t left waiting too long if OpenAI is slow.
o	Also consider streaming: OpenAI can stream responses. Implementing streaming in Next.js API and then to client (especially web) is possible, but complex. Likely we wonâ€™t stream for hack (weâ€™ll wait for full reply then send it).
â€¢	Supabase Functions (Edge): We arenâ€™t explicitly using Supabase Edge Functions in this design because Next.js covers our server needs. But they were an option. If Next wasnâ€™t in picture, we could have written a Supabase Edge Function for chat or feed. However, Nextâ€™s integrated approach is fine here.
â€¢	Real-time & Communications:
â€¢	Supabase Realtime: Under the hood, Supabase Realtime is built on Phoenix/Elixir. For us, we just use the client provided:
o	In Swift, the Supabase iOS library (or a separate realtime lib) will handle opening a WebSocket connection to wss://<supabase_project>.supabase.co/realtime/v1 and subscribing to channels.
o	In JavaScript (web), the supabase-js library uses a dependency (like @supabase/realtime-js) to do similarly. Weâ€™ll do something like supabase.channel('pets').on('postgres_changes', { event: 'UPDATE', schema: 'public', table: 'pets', filter: 'user_id=eq.<currentUserId>' }, payload => { ... }) to get events for our pet[8].
o	Those payloads give new and old record data for the change, which we use to update state.
â€¢	HTTP & Networking: All remote calls use HTTPS. The architecture calls for:
o	Device -> Supabase REST (HTTPS),
o	Device -> Next.js API (HTTPS),
o	Next.js -> Supabase (via Postgres connection, not HTTP),
o	Next.js -> OpenAI (HTTPS),
o	Supabase Realtime -> Device (WebSocket, which is also secure WSS).
o	This multi-channel network setup is supported by modern devices easily. We ensure endpoints and ports are configured (e.g., on iOS, allow outgoing connections to our supabase domain and next.js domain in Info.plist ATS if needed).
â€¢	DevOps & Tools:
â€¢	Version Control: Code will be managed in Git (GitHub possibly). Kiroâ€™s .kiro directory will be included to demonstrate usage of specs and hooks.
â€¢	CI/CD: If time permits, we might set up GitHub Actions for building/testing, and Vercel auto-deploys on git push. For iOS, we build locally (maybe use Xcode Cloud or TestFlight for distribution, not necessarily automated due to time).
â€¢	Testing Frameworks: Mentioned more in testing section, but in the stack: Xcodeâ€™s XCTest for iOS unit tests, Jest for any JS tests on Next side.
â€¢	Kiro Platform: (Development phase tool)
â€¢	Vibe Coding (Chat with Kiro): We used Kiroâ€™s conversational coding to generate boilerplate (for example, asking Kiro to create a SwiftUI view for the ghost AR screen based on our spec).
â€¢	Spec System: We maintain a spec document (this SRS doubles as a high-level spec; we may also distill it into a more implementation-focused spec file for Kiro). Kiroâ€™s spec-driven development feature allows us to outline structures (like data models, function stubs) and let Kiro fill them in.
â€¢	Agent Hooks: Some automated tasks during dev, e.g., a hook that whenever schema.prisma changes, Kiro runs prisma migrate dev and updates the database. Or a hook that on saving a Swift file, Kiro runs a build/test.
â€¢	Steering Documents: We have created a .kiro/steering/ios_guidelines.md to teach Kiro about SwiftUI best practices and maybe ARKit usage. Also a backend_guide.md to teach Kiro about Next.js and Prisma context (ensuring it writes code consistent with our stack). These steering files help Kiro produce better aligned code for our custom stack[14].
â€¢	Model Context Protocol (MCP): We configured Kiro to use an MCP connection to external docs (for example, hooking into Appleâ€™s Developer Documentation or Supabase docs). This means when coding, Kiro can fetch up-to-date information on ARKit APIs or Supabase usage as needed[15]. This extended Kiroâ€™s knowledge beyond its base training, which is extremely useful given the latest frameworks.
â€¢	While Kiro is not part of the deployed product, itâ€™s a crucial part of the tech stack in development, enabling rapid and AI-assisted coding which is a requirement of the hackathon.
In summary, the tech stack is a mix of modern, high-level frameworks (SwiftUI, Next.js, Prisma) and cloud services (Supabase, OpenAI) that together drastically reduce the need to build things from scratch (no need to manually build auth or websockets server â€“ Supabase does it; no need to create an AI model â€“ OpenAI provides it[2]). By choosing these, a solo developer can implement the complex Ghostagotchi app within a short timeframe.
Additionally, using Kiroâ€™s AI-powered development environment is an innovative part of the stack â€“ itâ€™s like having an AI pair programmer intimately integrated into our toolchain, which sets this project apart in terms of methodology.
10. Kiro Usage Plan (AI Development Workflow)
A significant aspect of this project is leveraging Kiro (the AI-powered IDE) throughout the development process. We have planned how to use each of Kiroâ€™s key features â€“ specs, agent hooks, steering, and MCP â€“ to maximize productivity and quality. This section outlines how Ghostagotchiâ€™s development was approached with Kiroâ€™s assistance:
â€¢	Spec-Driven Development (Kiro Specs): We begin by writing a comprehensive specification for the application within Kiro. In fact, this SRS document serves as the foundation for those specs. We distilled the requirements into a structured format that Kiroâ€™s spec engine can interpret. For example:
â€¢	A spec entry for the data model: we wrote a spec like â€œDefine a Pet model with fields: id (UUID), owner (foreign key), name, level, experience, hunger, mood... with given constraints.â€ Kiro then generated the corresponding Prisma model code based on this spec, saving time and ensuring consistency with our intent.
â€¢	A spec for a UI component: e.g., â€œSpec: Create an ARView in SwiftUI showing a ghost model and overlaying hunger/mood bars and feed/play/chat buttons.â€ Kiro uses this to produce a SwiftUI view code stub, which we then refine. By using spec prompts, Kiro could handle a lot of boilerplate (like setting up ARSessionRepresentable or SwiftUI layout code) much faster than writing from scratch.
â€¢	We maintain the spec as the source of truth. Whenever new features are decided (say adding the play action), we update the spec first. Then we instruct Kiro to implement according to the updated spec. This approach ensures we always have up-to-date documentation of the system and that the code generation stays aligned with requirements[16].
â€¢	The spec file is stored in the repository under .kiro/specs/ghostagotchi.md. It outlines modules (Database, iOS App, Web App, etc.) with checklists of tasks and definitions, which Kiro then uses one by one to generate or modify code. This yields a more organized development process and reduces errors from ambiguous instructions.
â€¢	Agent Hooks (Kiro Hooks): We automate repetitive workflows by setting up agent hooks in Kiroâ€™s environment[17]. Some hooks we use:
â€¢	Build & Test Automation: After each significant code generation or edit, we have a Kiro agent hook that automatically runs the build or test suite. For example, a hook triggers npm run build && npm run test for the Next.js app whenever we finalize a feature spec implementation. Similarly, after Kiro generates iOS code, a hook triggers an Xcode build (via xcodebuild command) or runs unit tests. This immediate feedback loop catches integration issues early. Kiro can monitor the output; if the build fails, Kiro can sometimes even suggest fixes (thanks to its coding AI) or automatically apply small corrections.
â€¢	Database Migration Hook: Whenever we modify the Prisma schema (either manually or via spec), a hook detects changes to schema.prisma and runs npx prisma migrate dev --name auto to apply the migration to the local dev database. Then it runs prisma generate to update the Prisma client. We also use a hook to deploy these migrations to Supabase (like running them against the Supabase connection string) so that the cloud database is in sync. This removes the manual step of toggling to a terminal and running migrations â€“ Kiro handles it, making our dev flow smoother.
â€¢	Code Linting/Formatting: We set up Kiro hooks to run SwiftFormat/SwiftLint on Swift code and ESLint/Prettier on JavaScript code whenever Kiro generates code. This ensures the code adheres to style guidelines automatically. Kiro either fixes issues itself or alerts us if something looks off. This was particularly useful when Kiroâ€™s generation was correct logically but needed tweaking to match style rules.
â€¢	Resource Automation: One creative hook â€“ when we added an image asset (like a ghost icon), we wrote an agent hook to optimize it (compress the PNG) and add it to the Xcode asset catalog automatically. This kind of file handling can be done with small scripts that the hook triggers.
â€¢	Documentation & Commit Hook: We have a hook set such that whenever we are about to commit or finalize a feature, Kiro updates a CHANGELOG.md or a development journal with what was done (based on our spec and commit message). This ensures we have documentation of how we utilized Kiro in each step, which is something judges might look for. Essentially, Kiro helps in summarizing how a spec was implemented, capturing that in a doc.
â€¢	These hooks improved our productivity by automating the â€œbusyworkâ€ of development â€“ compile, test, format, etc. â€“ letting us focus on core logic and spec refinement[18].
â€¢	Steering Documents (Kiro Steering): To get the best results from Kiroâ€™s code generation, we provided steering docs that guide its understanding of our project context and coding standards[14][19]. We created a few key steering files:
â€¢	Project Overview Steering: A markdown file summarizing Ghostagotchiâ€™s architecture, the frameworks used, and high-level conventions. For instance, it states: â€œWe use MVVM pattern in SwiftUI. Keep network code in a separate Service class. Use Combine for async updates.â€ By giving these hints, when we ask Kiro to implement a SwiftUI view, it will follow the MVVM approach (maybe creating a ViewModel if needed) rather than throwing everything in a single view struct. This makes the AIâ€™s output more maintainable.
â€¢	API & Library References: Instead of relying on Kiroâ€™s base training for specifics of ARKit or Supabase, we pruned and included relevant documentation in steering files:
o	An ios_arkit.md with concise ARKit usage tips (like how to place an entity, how to handle ARSession delegate). We refined such a file by including code snippets from Apple docs and then using Kiroâ€™s refine command to condense it[20].
o	A supabase_usage.md with examples of using Supabase client in Swift and JS, and explanations of our database schema context, so Kiro knows how we interact with the database.
o	A openai_integration.md with notes from OpenAI API docs (e.g., how to call their endpoints in Node, expected JSON structure).
â€¢	Style and Best Practices: We wrote a steering doc about code style and best practices (some of this Kiro knows, but we emphasize specifics):
o	For Swift: â€œUse camelCase for function names, use MARK comments to separate extensions, always unwrap optionals safely, add TODO comments if something is stubbed.â€
o	For React: â€œUse functional components with hooks, use useState/useEffect instead of class components, follow Next.js conventions for pages vs components, etc.â€
o	These help ensure the generated code doesnâ€™t deviate into an inconsistent style or outdated patterns.
â€¢	We kept the steering docs updated as the project evolved. For example, after we refined how we handle state in the iOS app (maybe deciding to use an ObservableObject for Pet state), we updated the steering file to instruct Kiro to always pass the PetViewModel to subviews rather than using global singletons. This way, subsequent code generations adhered to that architecture consistently[21].
â€¢	Kiroâ€™s ability to refine and compress steering docs was helpful â€“ we pasted some raw docs, then used the Refine feature to condense them to what's relevant[19]. This keeps Kiroâ€™s context focused.
â€¢	By using steering, we essentially â€œtrainedâ€ our Kiro AI on the specifics of Ghostagotchi, leading to more accurate and context-aware assistance from it.
â€¢	Model Context Protocol (MCP): Kiroâ€™s MCP feature allowed us to extend its knowledge by connecting to external sources in real-time[15]. We utilized MCP in a few ways:
â€¢	GitHub Repo Access: We configured a local MCP server for our Git repository. This means Kiro can fetch and read any file from our codebase as needed. For example, if weâ€™re editing something and Kiro needs to see how PetViewModel was defined, it can use MCP to open that file content as context. This cross-file awareness is crucial in a project with multiple components. It prevented mistakes like Kiro writing code that calls a function incorrectly because it could quickly check the function definition elsewhere in the project.
â€¢	Documentation MCPs: Kiro has connectors for certain documentation sources. We used one for Appleâ€™s Developer Docs and one for Supabase:
o	For Apple, whenever we were unsure about an ARKit method or SwiftUI API, instead of leaving the IDE to search online, we could prompt Kiro, and it would use MCP to pull relevant docs and incorporate it into its answer. For instance, â€œHow to use ARSCNView in SwiftUI?â€ Kiro might fetch the official snippet or explanation and then help integrate it. This saved time toggling between browser and IDE.
o	For Supabase, if Kiro needed the exact usage of say the supabase.from('pets').on('UPDATE') call, it could retrieve that from Supabaseâ€™s docs via MCP (assuming thatâ€™s supported). If not directly, we could have pointed Kiro to our own summarised docs in steering. But Kiroâ€™s MCP concept is beneficial for up-to-date info: if Supabase updated something or if we needed to confirm parameters, we have it at hand.
â€¢	StackOverflow MCP: Although not explicitly mentioned, Kiroâ€™s environment might allow searching programming Q&A. We could use it for odd issues (like a specific ARKit bug or a known workaround). This was less formal but sometimes asking Kiro leads it to search known solutions.
â€¢	The MCP usage ensured our development kept pace with current information and not just Kiroâ€™s training (which might be outdated on newer framework details). It is particularly relevant for any recent API changes â€“ for instance, if we were using the latest SwiftUI features from iOS 17, Kiro might not have them from training, but MCP to Apple docs would fill the gap[15].
â€¢	We essentially taught Kiro new â€œskillsâ€ or knowledge as needed by giving it these external hooks. This echoes exactly what Kiroâ€™s philosophy is â€“ â€œsteering and MCP to teach Kiro new skillsâ€[22], which we implemented by hooking in the references for our tech stack.
â€¢	Vibe Coding & AI Pair Programming: Although not explicitly asked in the prompt, vibe coding (conversational development) is a core part of using Kiro. We made heavy use of it:
â€¢	We would have chat sessions with Kiro to brainstorm implementations. For example, "Kiro, how should I structure the real-time update flow?" and Kiro (with context from specs and steering) would propose an approach (e.g., "Use Supabase's listener in the SwiftUI ViewModel to update @Published properties..."). These design conversations helped validate our plan or discover edge cases we missed.
â€¢	While coding, we often wrote a comment or partial function and then asked Kiro to complete it. Kiro could write significant portions of code (like the entire Swift class for ARCoordinator or a React component for the chat box) in seconds, guided by our instructions and the spec.
â€¢	One of the most impressive uses was generating tests: after writing a feature, we prompted Kiro â€œWrite unit tests for the feedPet function ensuring hunger doesnâ€™t exceed 100 and XP increments correctly.â€ Kiro then produced test code that we could run. This was a huge time saver in ensuring reliability.
â€¢	We also used vibe coding to generate content such as the ghost persona prompt for OpenAI. We asked Kiro to help craft a good system prompt based on the project theme ("friendly ghost, spooky puns, avoid adult content"), and it suggested a well-phrased prompt which we then used directly in our chat API route.
â€¢	Throughout these interactions, we documented what Kiro did, so we can later explain in our submission what tasks were AI-assisted (this is part of hackathon judging criteria on how effectively we used Kiro).
In summary, our plan was to treat Kiro not just as a code generator, but as an integral team member that enforces discipline via specs, automates tedious tasks via hooks, adapts to our project via steering, and broadens its knowledge via MCP. This allowed a single developer to manage the multi-technology scope of Ghostagotchi in a short time frame, effectively multiplying productivity.
By the time of submission, thanks to Kiroâ€™s features, we have: - A well-documented spec (this SRS) that matches the implementation (spec-driven dev). - Automated workflows that saved us time and prevented mistakes (hooks). - Code that is consistent and idiomatic in each language (steered by best practices docs). - Up-to-date solutions and usage of APIs (MCP to external docs). - And ultimately, a completed project that demonstrates not only a cool app but also cutting-edge development methodology.
This approach showcases our â€œnext-level understandingâ€ of Kiroâ€™s capabilities[23], aligning with hackathon expectations: we didnâ€™t just build Ghostagotchi, we built it the â€œKiro way,â€ leveraging AI at every step to push the boundaries of speed and integration.
11. Testing and Deployment Strategy
To ensure Ghostagotchi is robust and ready for demonstration, we have a clear testing plan and a deployment strategy for both the mobile and web components.
Testing Strategy
Testing Objectives: We want to validate that: - All core features work as intended (functional testing). - The app remains stable across typical use cases (stability testing). - Real-time synchronization is consistent (concurrency testing). - The AI responses are appropriate and the system handles edge cases (AI behavior testing). - Security measures (like RLS) are properly enforced (security testing).
Testing Approaches:
â€¢	Unit Testing:
â€¢	iOS: We write unit tests using XCTest for critical logic in the app. Since much of the iOS code is UI (which is harder to unit test), we focus on the view model and service layer:
o	Test the PetViewModelâ€™s logic, e.g., a method applyFeedResponse() that updates hunger and level. We simulate various scenarios (hunger at 90 -> feed -> should be 100, level up triggers correctly when XP over threshold, etc.).
o	If we have any standalone utility functions (like calculating time since last fed to reduce hunger), we test those thoroughly.
o	AR interface itself is tested mostly manually, but we can simulate ARKit not available scenarios in unit tests by injecting a mock ARSession to ensure our code handles it.
â€¢	Web: We use Jest (and React Testing Library) to test React components and utility functions:
o	Test that the Dashboard component renders correct info given a sample pet state.
o	Simulate user actions in tests: clicking Feed button calls the appropriate function or API (weâ€™ll mock the fetch call), and state updates as expected.
o	Test the Leaderboard list component to ensure it sorts and displays given data correctly.
o	Test any helper functions (like formatting or filtering logic).
o	We also test our Next.js API route logic as unit tests (this is possible by exporting handler functions and calling them with mock requests). For example, call our feedPetHandler with a fake request and a fake DB connection that returns known data, assert that it returns the expected new values or errors on invalid input.
o	Ensure our RLS policies are respected by tests: perhaps attempt a supabase query from a different userâ€™s perspective and confirm it fails (this would be an integration test with a test user).
â€¢	Backend Logic: We consider writing direct tests for Prisma-level logic as well:
o	Using a test database (or the Supabase database in a sandbox mode), run a migration then execute a scenario: create a user & pet, call the feed function or do an update, verify DB state changed correctly. These integration tests can be done with something like ts-node scripts or using a testing framework that can run against the DB. Alternatively, mocking Prisma calls for unit logic.
â€¢	We aim for key functions to be covered (not 100% coverage due to time, but at least for non-UI logic).
â€¢	Integration Testing:
â€¢	We perform end-to-end style testing to make sure all parts work together:
o	Manual Multi-Device Testing: We will run the iOS app (perhaps on a simulator and a real device) and the web app (in a browser) simultaneously with the same account to test real-time sync in practice. For example, feed on one and see update on the other, chat from one and see output on both, etc. This manual testing is crucial for real-time behavior which is hard to automate.
o	Automated E2E (if time): We might use a tool like Cypress or Playwright for the web part:
o	Example: Write a Cypress test that logs in a user on the web, triggers a feed action, then queries the database or uses Supabase client in test to verify the DB entry changed and maybe even check that the UI updated (Cypress can observe UI, though real-time aspects might need waits or mocking).
o	Another test: simulate two browser sessions (Cypress can spawn two windows) or use Playwrightâ€™s multi-page feature to simulate two users or two sessions of same user to see if an action in one is reflected in the otherâ€™s DOM.
o	For the mobile app, automated UI tests via Xcode UI Testing could simulate a few interactions: launch app (with a test user account pre-set), tap feed, assert that some UI element changed (like hunger label). But syncing with web in an automated way is complex, so that part is mostly manual or via logs.
â€¢	AI Response Testing: Testing AI is tricky since itâ€™s nondeterministic. But we can:
o	Use the OpenAI API in test mode with a known prompt to see if we get a sensible format (we canâ€™t assert exact text, but we can assert itâ€™s not empty and not an error).
o	Weâ€™ll test our system promptâ€™s effectiveness by trying some user messages that could be problematic and see how the ghost responds. For example, ask the ghost a question that might trigger the content filter or a tricky query, and verify it either refuses or responds in character.
o	If needed, adjust the prompt or add a basic content moderation check (OpenAI has a moderation API; we might not implement fully, but we ensure the ghost doesnâ€™t produce obviously disallowed content in our testing).
â€¢	Performance Testing: For real-time, measure roughly the lag:
o	We can add debug logs on iOS and web when they receive realtime updates, then perform an action and note timestamps to ensure itâ€™s within an acceptable range (< a second typically).
o	If things seem slow, investigate (maybe network issues or if our filter or subscription is misconfigured).
o	Also test that even with multiple rapid actions (like spamming feed or chat quickly), the system queues them properly (Supabase can handle moderate throughput, but weâ€™ll see that nothing crashes or data doesnâ€™t get corrupt).
â€¢	Security Testing:
o	Try to directly call our Next.js APIs with invalid tokens or no token to ensure they return 401.
o	Try to fetch someone elseâ€™s data by manipulating a supabase query (should be blocked by RLS â€“ we could test by using an admin key intentionally to mimic a malicious attempt, expecting it fails due to RLS).
o	Ensure that if we disable network mid-use, the app doesnâ€™t crash: On iOS, disable internet and try feed â€“ the supabase call should fail gracefully and show an error. Similarly on web, ensure our fetch calls handle errors (with catch).
o	We also test that logging out truly prevents access: after logout, the user shouldnâ€™t receive realtime updates or be able to call endpoints (the token is gone). We verify that scenario.
â€¢	Testing Kiro Integration: While not part of product runtime, we will gather evidence of Kiro usage:
â€¢	e.g., ensuring .kiro directory with spec and steering is present and that our commit history shows Kiroâ€™s contributions (to satisfy hackathon judging).
â€¢	Possibly run a small test by updating a spec and using Kiro to see if it correctly updates code (to be confident in Kiroâ€™s outputs which we have already integrated).
â€¢	Not a formal test, but more a preparation of usage documentation.
Test Environments: - We have a local dev environment (Supabase provides a local emulator, but we likely use the actual Supabase cloud dev project for testing to be closer to real environment). - Test data: Weâ€™ll create some test users (maybe via seed or manually using the app) to populate and test leaderboard scenarios, etc. - We ensure testing does not pollute production: for hackathon, â€œproductionâ€ is basically our final environment but we might treat the same Supabase project as both test and prod given scale. Weâ€™ll clean out test data or use distinct accounts for demo.
Bug Tracking and Fixing: - Weâ€™ll use GitHub issues or a simple TODO list to track any bugs found during testing. Kiro actually helps here too: we can describe a bug in a conversation and ask Kiro for help to fix it. For example, â€œThe hunger bar on web isnâ€™t updating until refresh, what could be wrong?â€ Kiro might remind us to call supabase.channel().subscribe() properly or flush a state. Using Kiro as a debugging assistant is part of our workflow.
Final Test Run (Demo Prep): Before submission, weâ€™ll do a clean run through of the entire user experience: - Create a new account, go through onboarding (ghost naming) â€“ verify pet created. - Try each feature in a logical sequence: feed ghost, see stat change; chat with ghost, get reply; let ghost sit and see if hunger decays (if implemented with time) or simulate time by adjusting code; view leaderboard (with at least one other dummy ghost to see ranking). - Do this on both iOS and web, and ideally with two devices concurrently. - Ensure the video demo script aligns with this so that everything shown has been tested beforehand.
Deployment Strategy
Backend (Supabase) Deployment: - We have set up a Supabase project for this hackathon. During development, we applied migrations to it. For production use (the demo), the Supabase project itself is already â€œliveâ€ (since itâ€™s cloud). We just need to ensure it has all latest schema changes and the right security policies. - We will use the Supabase web portal or supabase CLI to verify: - Tables and relationships are correctly created. - RLS policies are enabled on pets, messages, etc., and tested. - Enable any required Auth providers (like if we allow Google login, configure client IDs). - Set up storage bucket if needed (maybe not needed, unless we do something like storing ghost images). - We also check Supabase API settings: For instance, if we decided to use Prisma exclusively, Supabase suggests disabling the â€œData APIâ€ (PostgREST) to avoid conflicts[13]. However, we might leave it on for flexibility (and itâ€™s needed for realtime anyway). No strong changes needed there. - We store configuration values in Supabase (like maybe using their vault for secrets if any needed â€“ but our main secret is OpenAI key which we keep in Next, not in DB). - The Supabase instance will be hosted (likely on AWS infrastructure by Supabase). Itâ€™s accessible via internet, so our clients just need the URL and anon key.
Web App Deployment: - We plan to deploy the Next.js application on Vercel. Vercel is ideal because: - It supports Next.js SSR and API routes out of the box. - It provides a domain (we might get a *.vercel.app domain for the project). - We can easily set environment variables on Vercelâ€™s dashboard: - SUPABASE_URL, SUPABASE_ANON_KEY for the client usage. - SUPABASE_SERVICE_ROLE_KEY (if we use it in server for admin queries). - DATABASE_URL for Prisma (connection string to Supabase DB â€“ we will use the postgresql:// connection string provided by Supabase). - OPENAI_API_KEY for the chat function. - Weâ€™ll set up automatic deployment from our repositoryâ€™s main branch. So pushing to main will trigger a Vercel build (which runs npm install && npm build). The build will also run our tests (if we configure it to run tests, we might do that to catch any last-minute issues). - Vercelâ€™s serverless functions have limits (like 10s execution). Our OpenAI call could approach that if slow, but GPT-4 usually responds within ~5-6s for short queries. We should be okay; otherwise consider using streaming or returning 408 after a threshold. For now, assume itâ€™s fine. - Once deployed, weâ€™ll test the live URL and ensure all features work with the live Supabase. We need to ensure CORS and such are configured (Supabase by default allows requests from anywhere for the anon key, but our Next API should be same domain as web so no major CORS issue). For mobile though, the iOS app calling Next.js API might be cross-domain; weâ€™ll ensure our Next.js API routes either allow that domain or we could unify domain names via config.
â€¢	iOS App Deployment:
â€¢	Since this is a hackathon, we are not releasing on the App Store. Weâ€™ll use TestFlight or simply build on a device for demo:
o	Weâ€™ll archive the app and distribute via TestFlight to any testers (like hackathon judges if they want to try, we could provide an invite code).
o	Alternatively, just use an iPhone plugged in during demo or screen recording from simulator for the video.
â€¢	We need to ensure the app is built in Release mode for performance (AR in debug can be slower).
â€¢	We'll embed configuration in the app (like Supabase URL, anon key, and the Next.js API base URL). Possibly we point to the Vercel domain for API, which is fine as long as we handle https. Weâ€™ll add an entry in Info.plist for App Transport Security if needed to allow our domain (ensuring itâ€™s https means we might not need exceptions).
â€¢	If using TestFlight:
o	Weâ€™ll register necessary Apple IDs for testers.
o	Because of time constraints, this might be optional; a local build might suffice for demonstration.
â€¢	We double-check that the app works on a real device with camera (since AR on simulator just uses a static image or doesnâ€™t fully work). Weâ€™ll test on at least one iPhone to confirm AR ghost appears, etc., prior to demo.
â€¢	DNS and Domain (if any):
â€¢	For user-friendliness, we could set a custom domain for the web (if provided by hackathon or if we have one). But itâ€™s not necessary; the Vercel link is fine to share.
â€¢	The Next.js API will be accessible under that same domain, which the mobile app needs. We might hardcode the domain in the app. Alternatively, we can use a configuration file or environment in iOS for easier change if needed.
â€¢	Monitoring & Logging:
â€¢	Weâ€™ll monitor Supabase logs (thereâ€™s a section for Postgres logs, etc.) during testing for any errors (like RLS policy denials or any SQL errors).
â€¢	Also monitor the Next.js function logs on Vercel (they have a console for function invocations) to see if any errors occur when hitting the endpoints.
â€¢	If any crashes or unexpected issues appear in logs, fix before final demo.
â€¢	On the iOS side, we might include some runtime logging (print statements) that we can see in Xcode console during test. In TestFlight, we can use TestFlightâ€™s feedback logs if testers see a problem.
â€¢	We are essentially the ones operating it for demo, so active monitoring is just through our own observation in tests.
â€¢	Backup Plans:
â€¢	If the Next.js server fails (for example, OpenAI quotas exhausted or an unfixable bug), we can degrade gracefully: ghost chat might show a default â€œGhost is tired, cannot talk now.â€ Not ideal, but at least the appâ€™s other features (AR pet, feeding, leaderboard) still showcase the multi-tech integration.
â€¢	If realtime doesnâ€™t work due to firewall or something in demo environment, we can manually refresh to show state sync (less impressive, but ensures functionality).
â€¢	Weâ€™ll keep the OpenAI usage within free trial or budget, but have a note: if we hit rate limit, possibly switch to a lesser model or have a cached example response to show.
â€¢	Ensuring offline: if internet drops in demo, we have a video as backup or the app can still show AR ghost doing something (just not updating or chatting).
Deployment Timeline: - We plan to freeze code by [a couple days before deadline] and focus on testing and bugfix. Then: - Deploy final backend (migrations applied) by that day. - Deploy front-end to Vercel (which is quick). - Build final iOS binary and distribute (or at least have it on device). - This timeline gives a buffer to resolve any last deployment-specific issues (like environment variables or domain config). - We also prepare the 3-minute demo video around that time, which effectively double-checks that our deployed app works end-to-end in a real scenario (since weâ€™ll capture actual usage in the video).
By following this testing and deployment plan, we aim to present Ghostagotchi as a fully functional, well-tested prototype at the hackathon. The strategy ensures that the judges can interact with the app (via the web link or TestFlight) without encountering glaring issues, and that the projectâ€™s complexity (multi-platform + real-time + AI) is delivered smoothly. We also demonstrate good software engineering practices by having tests and a considered deployment, which underscores the completeness and professionalism of the project.
12. Development Phases
Building Ghostagotchi within the hackathon period required careful planning and phased development. Below we outline the key development phases, roughly in chronological order, along with their main tasks and milestones:
1.	Phase 1: Planning & Setup (Day 1-2) â€“ Objective: Lay the groundwork for development.
2.	Define core concept and scope: We decided on the feature set (AR pet, AI chat, cross-platform sync, leaderboard).
3.	Set up project repositories and environments: Initialize a Git repository. Create the Supabase project and configure initial settings (enable email auth, etc.). Set up the Next.js project (npx create-next-app) and iOS Xcode project.
4.	Write the initial spec (SRS) for the app (much of this document). This includes architecture decisions and data model outline.
5.	Configure Kiro environment: Ensure we have Kiro IDE or CLI set up. Create initial .kiro/specs and add basic steering docs (like the chosen tech stack descriptions).
6.	Run a quick tech spike: e.g., build a minimal ARKit SwiftUI app to confirm AR works, and a minimal Supabase query from Swift to confirm connectivity. Likewise, test Supabase JS in a Node context for a trivial query to ensure DB connection works with Prisma or client.
7.	Milestone: By end of Phase 1, we have a clear plan (this SRS completed in draft) and all tools configured (Supabase, Kiro, dev environment). No major coding yet, but everything is scaffolded (blank Next.js app up on localhost, iOS app runs a blank screen on device).
8.	Phase 2: Backend Foundation (Day 3-4) â€“ Objective: Build the database and backend logic early, as itâ€™s central.
9.	Design the data schema in Prisma (models for Profile, Pet, Message). Run prisma migrate to apply it to Supabase. Adjust any Supabase-specific things (like enabling uuid-ossp extension if needed).
10.	Implement Row Level Security policies on tables and test them with dummy users.
11.	Write initial Next.js API routes:
o	e.g., /api/pet GET to retrieve pet, and /api/pet POST to create pet. Test these with curl or a REST client.
o	Possibly implement a simple feed endpoint (can stub logic first).
o	Implement a basic /api/chat that calls OpenAI with a sample prompt (without integration to DB yet).
12.	Set up OpenAI API key in a local .env and test the chat endpoint standalone by sending a curl request and seeing a response.
13.	By using Kiroâ€™s spec and generation, many of these steps are accelerated. We have Kiro generate the Prisma schema from our spec, Kiro generate boilerplate for Next.js routes.
14.	Milestone: End of Phase 2, the database is ready and core backend endpoints exist (though frontends not using them yet). We can manually hit an endpoint to create a pet and then see that pet in DB, etc. The hardest logic (like level-up in feed) might be stubbed, but basic functionality works.
15.	Phase 3: iOS App â€“ Core Features (Day 5-7) â€“ Objective: Get the iOS app functional with AR, pet status, and integrate with backend.
16.	Implement authentication flow on iOS (using Supabase Auth). Possibly use a basic SwiftUI form for login. Test logging in with a Supabase test account.
17.	After login, implement ghost creation flow: If no pet in DB, show a form to name ghost, call the /api/pet or use Supabase client to insert. Ensure once created, we fetch and store pet info.
18.	AR view: Load a 3D ghost model (could be a simple SceneKit scene with a SCNNode in shape of ghost or use RealityKitâ€™s built-in shapes with transparency). Use ARKit to display it. This might involve some trial with AR anchors.
19.	Overlay UI: Show ghostâ€™s name and stat bars. They can be static values initially.
20.	Actions: Implement the Feed button â€“ on tap, call our backend (either supabase RPC or Next.js API route). For now, even a dummy call that sets hunger to 100 directly via Supabase client is okay; later, replace with calling our feed endpoint.
21.	Subscribe to realtime: using Supabaseâ€™s Swift library, subscribe to changes on the pet row. Test by manually changing DB entry to see if iOS receives it (e.g., change hunger in DB and watch iOS console log).
22.	Chat UI: A basic view with a TextField and a list for messages. Hook it up to call /api/chat and append the response. Possibly use Combineâ€™s Future to handle the async call. Kiroâ€™s help here is used to quickly draft this.
23.	Use placeholders or simplified interactions to test each piece: e.g., initially, pressing Feed could just locally set hunger to 100 to see UI update, before backend wiring is done.
24.	Milestone: End of Phase 3, the iOS app is mostly functional locally: user can log in, see ghost in AR, press Feed and hunger bar changes (maybe round-trip with DB), and even send a chat and get a response from OpenAI. Some adjustments might be needed on ghost model appearance and UI polish, but core flows work at least in dev environment.
25.	Phase 4: Web Dashboard â€“ Core Features (Day 8-10) â€“ Objective: Build the Next.js web interface and ensure parity with iOS features.
26.	Implement login page using Supabase JS (or NextAuth with supabase, but supabase-js is straightforward for hack). Test login with same account as iOS to ensure working.
27.	Build Dashboard page:
o	Fetch pet data on load (via server-side props or client useEffect with supabase).
o	Display pet info and actions (feed, play, chat).
28.	Implement realtime subscription in web: use supabase.channel() or older supabase.from('pets') to onUpdate. When event comes, update React state. Test by having iOS feed and see web state update.
29.	Chat component: similar to iOS, call /api/chat via fetch, display reply.
o	We ensure to handle session token: maybe use supabase.auth.session() to get current JWT and include in fetch headers.
30.	Leaderboard page: Query top pets via a serverless function or directly with supabase (but because of RLS, likely through our /api/leaderboard route using service key). Render the list.
31.	Basic CSS styling to make it presentable. Use Tailwind to quickly space things and apply colors. Ensure it looks okay on mobile sizes too.
32.	Test web functionalities on its own and in conjunction with iOS (e.g., open web and iOS side by side).
33.	Milestone: End of Phase 4, the web app does everything the iOS app does, and they interoperate. The ghost state is truly shared. Possibly all major features are implemented albeit in basic form.
34.	Phase 5: Refinement & Polish (Day 11-13) â€“ Objective: Improve usability, fix bugs, and add any bonus enhancements.
35.	UI/UX Polish:
o	Make the iOS AR experience smoother (adjust ghost scale, maybe add an animation).
o	Add feedback on actions (like a little ghost animation or sound on feed, or loading spinners during chat).
o	Apply spooky theme visuals: e.g., set a dark theme background on web, use ghost emoji icons, maybe a custom font for headings.
o	Ensure consistency between platforms (use the same ghost name and stat terminology).
36.	Performance tweaks:
o	On iOS, ensure realtime subscription doesnâ€™t flood UI (maybe use debounce if necessary).
o	On web, possibly implement a small delay or visual effect for realtime updates to look nice (like highlight changed value).
o	If AI responses are long, consider trimming or instructing OpenAI to be concise to keep UI clean.
37.	Complete any incomplete features:
o	If mood mechanic or play action was left out, implement now if time allows.
o	If ghost hunger decay over time is desired, implement a simple mechanism (maybe a scheduled function on supabase or in client that reduces hunger every X hours). If time is short, document it as future work.
38.	Cross-platform edge cases:
o	What if user logs in on web without creating ghost (maybe they skipped on iOS)? Ensure web handles prompting to create ghost too.
o	Logout flows: test logging out and back in.
o	Multi-user: Create a second user with their ghost, ensure leaderboard shows both correctly and one user canâ€™t affect anotherâ€™s data.
39.	Use Kiro to speed up any remaining coding or to refactor (maybe we ask Kiro to refactor some repeated code into a shared module, etc.).
40.	Milestone: End of Phase 5, the application should be feature-complete and polished. We should be ready to present it. Internal testing should show no major issues.
41.	Phase 6: Testing & Fixes (Day 14-16) â€“ Objective: Rigorously test the whole system and fix any discovered bugs.
42.	Conduct the testing plan (unit tests, integration tests, manual scenarios as described in section 11). This will likely uncover some issues (for example, maybe a realtime event not received in certain condition, or a UI glitch).
43.	Use Kiro to help fix issues: for instance, if a test fails, feed the error to Kiro to get suggestions.
44.	Optimize any slow parts: maybe initial load is slow due to waiting on both profile and pet fetch; solve by combining queries or SSR.
45.	Finalize content: ensure all text (like ghost responses, UI labels) have no typos and are in a fun tone.
46.	Get a friend or team member to beta test if possible and incorporate feedback on usability.
47.	Milestone: End of Phase 6, all tests should pass and we have a stable release candidate.
48.	Phase 7: Deployment & Demo Prep (Day 17-18) â€“ Objective: Deploy the app and prepare submission materials.
49.	Deploy Next.js to Vercel (if not already done continuously, do final deploy).
50.	Archive iOS app and deploy to TestFlight (if doing so) or prepare the device for live demo.
51.	Do a final sanity check on production environment: create a new account, go through flow.
52.	Prepare the demo video: script the user journey and record it (the video likely shows both web and iOS; maybe side by side or sequentially).
53.	Write project documentation (README with setup instructions, usage of Kiro, etc. â€“ a lot of that comes from this SRS, we can trim it for README).
54.	Ensure the .kiro directory is present in repo with spec, hooks, etc., to showcase our Kiro usage as required[24].
55.	Submit to Devpost with required info (screenshots, video, etc.).
56.	Milestone: Ghostagotchi is delivered successfully to the hackathon judges for evaluation.
(Timeline note: Given the hackathon runs ~5 weeks, we have outlined ~18 days of active dev above, leaving buffer days for any delays, additional features, or simply because not every day is full-time. The ordering is flexible; sometimes web and iOS dev overlapped to not idle. The priority was to get core cross-platform functionality done early so we have time to iterate.)
Each phase leverages Kiroâ€™s assistance to keep us on schedule. For example, in phases where similar functionality is built twice (iOS and web), Kiro helped ensure we didnâ€™t have to â€œrewriteâ€ logic manually in two languages â€“ we often wrote the spec once and used Kiro to generate both Swift and TS implementations from that same spec, adjusting as needed. This parallel development through AI significantly compressed the timeline.
By following these phases, we systematically tackled the projectâ€™s challenges. Starting from a solid spec and backend, then focusing on one platform at a time, ensured we always had a working baseline to integrate with. The final phases of testing and polish were crucial given the multi-faceted nature of Ghostagotchi â€“ they allowed us to refine the user experience and ensure reliability despite the complexity.
 
With the above Software Requirements Specification, we now have a comprehensive guide to Ghostagotchiâ€™s intended functionality, design, architecture, and development process. This SRS will serve as a reference throughout implementation and will be part of the documentation provided to hackathon judges to illustrate the thorough planning and completeness of the project.
References:
â€¢	Kiroween Hackathon details and criteria[25][26]
â€¢	Supabase Documentation for Auth and Realtime[6][4]
â€¢	OpenAI Integration reference (Natively.dev)[2][3]
â€¢	Kiro features and usage guidelines[15][17]
 
[1] [25] This is Kiroween - Kiro
https://kiro.dev/blog/kiroween-2025/
[2] [3] How to Integrate OpenAI into Mobile Apps: Beginnerâ€™s Guide
https://natively.dev/blog/how-to-integrate-openai-into-mobile-apps
[4] [7] [8] [9] Realtime | Supabase Docs
https://supabase.com/docs/guides/realtime
[5] [16] [17] [18] [22] [23] [24] [26] Kiroween: Build something wicked for Kiroween, our annual Halloween-themed hackathon where developers dare to code in dark mode - Devpost
https://kiroween.devpost.com/
[6] [10] [11] Auth | Supabase Docs
https://supabase.com/docs/guides/auth
[12] I'm trying to choose between Supabase and Postgres+Prisma for my Next.js project. Which one is better, how do you decide which one to pick? : r/nextjs
https://www.reddit.com/r/nextjs/comments/uhz3gu/im_trying_to_choose_between_supabase_and/
[13] Prisma | Supabase Docs
https://supabase.com/docs/guides/database/prisma
[14] [15] [19] [20] [21] Teaching Kiro new tricks with agent steering and MCP - Kiro
https://kiro.dev/blog/teaching-kiro-new-tricks-with-agent-steering-and-mcp/
